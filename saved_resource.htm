 <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- saved from url=(0022)https://wlouyang.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Wanli Ouyang - Homepage</title>

<!--- <link rel="shortcut icon" type="image/ico" href="http://www.interdigital.com/idsystem/favicon.ico"><link rel="stylesheet" type="text/css" href="style.css" media="screen"> -->
 <script type="text/javascript" src="jsript.js"></script>  

<style type="text/css">@import url( style.css );
DIV.b-mobile {
	DISPLAY: none
}
</style>

<meta name="GENERATOR" content="MSHTML 8.00.6001.18852">
</head>

<body style="VERTICAL-ALIGN: middle">
<table border="0" cellspacing="0" cellpadding="0" width="100%">
  <tbody>
  <tr>
    <td><a name="Top"></a>
      <center>
      <!--================================Begin of Header of Windows Body====================================-->
      <table style="BACKGROUND-IMAGE: url(wave.jpg); BACKGROUND-REPEAT: no-repeat;BACKGROUND-POSITION:center" border="0" cellspacing="0" cellpadding="0" width="100%">
        <tbody>
        <tr>
          <td>
            <center>
            <table style="TEXT-ALIGN: left; WIDTH: 900px" border="0" cellspacing="0" cellpadding="0">
              <tbody>
              <tr>
                <td class="item"><a href="#Top">Home</a></td>
                <td class="item" style="WIDTH: 40px"></td>
                <td class="item"><a href="#Biography">Biography</a></td>
                <td class="item" style="WIDTH: 40px"></td>
                <td class="item"><a href="#Education">Education</a></td>
                <td class="item" style="WIDTH: 40px"></td>
                <td class="item"><a href="#Research">Research</a></td>
                <td class="item" style="WIDTH: 40px"></td>
<!--                <td class="item"><a href="http://www.h265.net/" target="_blank">Blog</a></td>  -->
                <td style="WIDTH: 540px"></td></tr>
             <tr><td style="HEIGHT: 30px;WIDTH: 900px" colspan="12"></td></tr></tbody></table></center>
          </td></tr></tbody></table>
<!--================================End of Header of Windows Body====================================-->

<!--================================Begin of Body of Windows Body====================================-->
            <table id="main" border="0" cellspacing="0" cellpadding="0" width="900">
              <tbody>
              <tr>
                <td style="BACKGROUND-COLOR: #fcfcfc; WIDTH: 100%; OVERFLOW: hidden" valign="top">
                
                  <div id="divContentHome" class="content_div_block">
                  <table class="garde_table_photo" align="center" border="0">
                    <tbody>
                    <tr>
                      <td style="width:412px;height:200px;background-color: #FFFFFF; font-family:garamond; font-size:13px; padding: 10px 20px 10px 20px ; border: 1px solid #D2D2D2;">
                      	<table>
							<tbody><tr>
								<td colspan="2" style="width:165px; height:44px;"><a href="https://sydney.edu.au" target="_blank"><img src="Resources/Icons/usyd-icon.png" height="120px"></a></td>								
<!--								<td colspan="2" style="width:412px; height:44px;"><img src="cu-hk-university.jpg" alt="CUHK" width="308px" height="70px"></td> -->
							</tr>
							<tr>
								<td colspan="2" style="width:412px; height:20px;"></td>
							</tr>
							<tr>
								<td colspan="2" style="width:412px; height:22px;"><b style="font-family:garamond; font-size: 19px;font-weight: bold;">Wanli Ouyang, Ph.D, IEEE Senior Member.</b></td>
							</tr>
							<tr>
								<td colspan="2" style="width:412px; height:22px;"> <b style="font-family:garamond; font-size: 15px;">Senior Lecturer at the University of Sydney</b></td>
							</tr>
							<tr>
								<td colspan="2" style="width:412px; height:22px;"> <b style="font-family:garamond; font-size: 15px;">I'm with <a class="aLink" href="http://mmlab.ie.cuhk.edu.hk/" target="_blank"><i> MMlab </i></a> and <a class="aLink" href="https://sigmalab-usyd.github.io/" target="_blank"><i> SIGMA lab</i></a> </b></td>
							</tr>
						</tbody></table>
						<table cellspacing="0" cellpadding="0" border="0" width="100%">
							<tbody><tr>
								<td bgcolor="#0099FF"><img src="transparent.gif" alt="" width="1" height="1" border="0"></td>
							</tr>
						</tbody></table>
						<table>
							<tbody><tr>
								<td style="width:210px; height:44px; line-height:125%; ">
								<a class="aLink" href="https://sigmalab-usyd.github.io/" target="_blank"> SIGMA lab</a>, <a class="aLink" href="https://sydney.edu.au/engineering/about/school-of-electrical-and-information-engineering.html" target="_blank"> School of Electrical and Information Engineering, </a> <br>
								<a class="aLink" href="https://sydney.edu.au/" target="_blank"> The University of Sydney, </a> <br>
								Sydney, Australia<br>
								</td>
								<td style="width:182px; height:44px; line-height:125%; text-align:left;">
								<br>
								<br>
								<img src="mainpa1.gif" alt="CUHK" width="80px" height="12px">sydney.edu.au<br>
								</td>
							</tr>
						</tbody></table>
<!--						<table>
							<tbody><tr>
								<td colspan="2" style=" line-height:50%; text-align:center;VERTICAL-ALIGN:middle; width:356px; height:10px;">www.interdigital.com</td>
							</tr> 
						</tbody>
						</table>-->
                      </td>
                      <td width="150px"></td>
                      <td style="VERTICAL-ALIGN: middle; width:120px"><img alt="Photo" src="Wanli-New.jpg" width="180px" height="200px"></td>
                      <td width="167px"></td>
                     </tr>
                    </tbody>
                  </table>
				  </div>
                  <div id="divContentBiography" class="content_div_block"><a name="Biography"></a>
                  <h1>Biography</h1>
                  <p class="garde_p">
                  	Wanli Ouyang obtained Ph.D from <a class="aLink" href="http://www.ee.cuhk.edu.hk/" target="_blank">  the Dept. of Electronic Engineering </a>, 
                  	the Chinese University of Hong Kong. 
                  	He is now a Senior Lecturer (equivalent to associate professor in US university systems) at the University of Sydney.
                  	His research interests include deep learning and its application to computer vision and pattern recognition, image and video processing.  <br><br> 

<!-- Dr. Dong received the B.Eng. and M.Eng. degrees, both in Information Engineering from 
                  <a class="aLink" href="http://www.zju.edu.cn/english/" target="_blank">Zhejiang University</a>, Hangzhou, China, 
                  in 2002 and 2005, respectively, and received the Ph.D. degree in Electronic Engineering in 2009, from 
                  <a class="aLink" href="http://www.cuhk.edu.hk/english/" target="_blank">the Chinese University of Hong Kong</a>, 
                  Hong Kong, China, where she worked as a Postdoctoral Fellow in the following year. In 2011,
                  she joined the CTO Office of 
                  <a class="aLink" href="http://www.interdigital.com/" target="_blank">InterDigital Communications</a>, U.S.A.,
                  as Staff Engineer. From 2003 to 2009, she was an active participant in Chinese standardization for 
                  multimedia with successful submissions to 
                  <a class="aLink" href="http://www.avs.org.cn/english/" target="_blank">AVS workgroup</a>. She has been engaged in 
                  HEVC standardization effort since 2011. 
                  Her research interests include high efficiency video coding and real-time video processing.<br><br> -->
				  <a target="_blank" class="aLink" href="./CV_WanliOuyang_CUHK.pdf"><img src="Resources/Icons/pdf-icon.png" width="15px" height="15px" alt="CV PDF" border="0"> Download Wanli Ouyang's Full CV</a>
				  &nbsp;&nbsp;&nbsp;&nbsp;
				  <a target="_blank" class="aLink" href="http://hk.linkedin.com/pub/wanli-ouyang/24/61b/293">
				  <img src="Resources/Icons/linkedin-icon.png" width="15px" height="15px" alt="View Wani Ouyang&#39;s LinkedIn Profile" border="0">View Wanli Ouyang's LinkedIn Profile</a> 
				  &nbsp;&nbsp;&nbsp;&nbsp;
				  <a target="_blank" class="aLink" href="http://scholar.google.com/citations?user=pw_0Z_UAAAAJ&amp hl=en">
				  <img src="Resources/Icons/google-icon.png" width="15px" height="15px" alt="View Wani Ouyang&#39;s Google Scholar Citations" border="0"> View Wanli Ouyang's Google Scholar Citations</a><br><br>
                  <a class="aLink" href="./#Top">Back To Top</a> <br><br> </p>
</div>
                  <h1>Information for potential Postdoctoral Fellow, Master and Ph.D. students and Final Year Program students </h1>                   
                  I moved  <a href="http://sydney.edu.au/engineering/electrical/"> the School of Electrical and Information Engineering, University of Sydney </a> as senior lecturer on 2017. 
                  If you are interested in my research topic and this university, please feel free to contact me <strong> after reading the information available <a href="https://sigmalab-usyd.github.io/recruitment/"> here</a> </strong>.
                  <h1>News </h1>                   
									International Journal of Computer Vision (IJCV) <strong><a href="http://www.ee.oulu.fi/~lili/IJCVSIEVR2018.htm">Special Issue on Efficient Visual Recognition </a></strong>. Due date for submission of full papers: February 15, 2019.
									<br>	<br>
									
                  <h1>Talks </h1>
<a href="./talk/Wanli_AutoML.pdf"> My recent talk on 'From Manual Design to Automatic Deep Learning'</a>
<br> <br>
<a href="./talk/Tutorial_2019_China_PRCV_out.pdf"> My recent tutorial on 'Deep learning in object detection' at PRCV 2019 </a>
<br> <br>
<a href="./talk/Talk2019_China_Jan_4_out.pdf">  My recent talk on ‘Structured deep learning for visual localization and recognition’  </a>
<br> <br>

<a href="./talk/ACCV18_3D_scene_understanding.pdf">  My talk ‘Modeling deep structures for 3D scene understanding’ at ACCV 2018 workshop </a>
									<br>	<br>

<a href="./talk/ACCV18_High_Performance.pdf">  My talk ‘Modeling deep structures for using high performance images’ at ACCV 2018 workshop </a>
<br> <br>




<!----																	<a href="./projects/GBD/index.html">Our team rank as #1 for object detection with provided data and external data and #1 for video object detection/tracking in the ImageNet Large Scale Visual Recognition Challenge 2016. Project page with source code </a> <br /> -->

                  <h1>Good resources on Paper Writing </h1>         
                  <a href="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&mid=2649439633&idx=1&sn=f9a6b894e4266a6e5ec4b6ec673255a2&chksm=82c0d415b5b75d03faa511eb691630d2e5d3ed2fbe3598629ab20a037b8d95bfa5c795ad1c66&mpshare=1&scene=1&srcid=1205JJGMMw3BmvYdPXJBrNyq##"> How to do good research on computer vision (Chinese) </a> <br />                            
                  <a href="http://ec.europa.eu/eurostat/documents/64157/4374310/33-UNECE-making-data-meaningful-Part2-EN.pdf/d5b954e2-b110-469b-a2b5-78aa7c12ab62"> Making Data meaningful </a> <br />
                  <a href="https://www.dropbox.com/s/wgrdpmxcmb4nhl0/How%20to%20Get%20Your%20CVPR%20Paper%20Rejected.pptx?dl=0"> Slides on "How to get your paper rejected." By Prof. Ming-Hsuan Yang from UC Merced </a> <br />
                  <a href="http://blog.csdn.net/daiyuchao/article/details/6419543"> Chinese blog on how to publish a top journal </a> <br />

                  <h1>Good advices for Research Students</h1>         
                  <a href="https://mp.weixin.qq.com/s?__biz=MzI0NTY5ODMzMQ==&mid=2247485969&idx=1&sn=0766ff7f65828486725c722c88101a07&chksm=e94bd065de3c59735e2e3876c74e646d2c87e6acdf17157cddcc7fca02afe6261fcbf88b75db&mpshare=1&scene=1&srcid=0207ALoWRslZQnzDDYaKeUNw#rd"> 研究生导师：这种学生，才是我眼中的科研好苗子！(Advice in Chinese)</a> <br />


<!--                   <a href="./projects/ImageNet/index.html">Our team rank as #1 for video object detection and #2 for still image object detection in the ImageNet Large Scale Visual Recognition Challenge 2015. Project page</a> <br />
                  <a href="./projects/ImageNet/index.html">Our team rank as #2 in the ImageNet Large Scale Visual Recognition Challenge 2014. Project page</a> <br /> -->


<!--========================  Recommendation on Papers  ==========================--> 
<div id="divContentResearch" class="content_div_block"><a name="Research"></a>
                  <h1>Chef's Recommendation on Papers </h1>

                  <em> Our recent survey on object detection: </em>   <br>
                  
                  Dongzhan Zhou, Xinchi Zhou, Wenwei Zhang, Chen Change Loy, Shuai Yi, Xuesen Zhang, <strong>Wanli Ouyang</strong>, “EcoNAS: Finding Proxies for Economical Neural Architecture Search”, Proc. <em>CVPR</em>, 2020.
                        <br>  <br>


									Liu, Li, <strong>Wanli Ouyang</strong>, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, and Matti Pietikäinen, "Deep learning for generic object detection: A survey,"  <em>IJCV, accepted</em>, 2019.
												[<a class="aLink" href="https://arxiv.org/pdf/1809.02165" target="_blank">Full Text</a>]
                        <br>  <br>

								
									<em> A new back-bone deep model design (performs better than ResNet and DenseNet): </em>   <br>
									Shuyang Sun, Jiangmiao Pang, Jianping Shi, Shuai Yi, <strong>Wanli Ouyang</strong>, "FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction,"  <em>NuerIPS. (Previously called NIPS)</em>, 2018.
												[<a class="aLink" href="http://papers.nips.cc/paper/7356-fishnet-a-versatile-backbone-for-image-region-and-pixel-level-prediction.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" href="https://github.com/kevin-ssy/FishNet" target="_blank"> Source code </a>]
                        <br>  <br>

									<em> The first end-to-end deep video compression model: </em> <br>
									Guo Lu, <strong>Wanli Ouyang</strong>, Dong Xu, Xiaoyun Zhang, Chunlei Cai, Zhiyong Gao, "DVC: An End-to-end Deep Video Compression Framework," In Proc. CVPR 2019. 												[<a class="aLink" href="https://arxiv.org/pdf/1812.00101" target="_blank">Full Text</a>]  [<a class="aLink" href="https://github.com/GuoLusjtu/DVC" target="_blank">Source code</a>]
                        <br>  <br>

									<em> Details on our wining entry in ImageNet 2016 challenge on object detection: </em>   <br>
                      	Xingyu Zeng (equal contribution), <strong>Wanli Ouyang</strong> (equal contribution), Junjie Yan, Hongsheng Li, Tong Xiao, Kun Wang, Yu Liu, Yucong Zhou, Bin
Yang, Zhe Wang, Hui Zhou, Xiaogang Wang,
                      "Crafting GBD-Net for Object Detection," 
                      <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, accepted, 2017.
												[<a class="aLink" href="./Papers/Zeng2017_GBD_PAMI.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" href="./projects/GBD/index.html" target="_blank">Project page & code </a>]												
												[<a class="aLink" href="https://github.com/craftGBD/craftGBD" target="_blank"> Source code </a>]
                        <br>  <br>


<em> The first work modeling deformation in deep CNN, used for pedestrian detection: </em>   <br>
                      	<strong>Wanli Ouyang</strong>, Hui Zhou, Hongsheng Li, Quanquan Li, Junjie Yan, Xiaogang Wang,
                      "Jointly learning deep features, deformable parts, occlusion and classification for pedestrian detection," 
                      <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, 40(8):1874-1887, 2018.
												[<a class="aLink" href="./Papers/Ouyang2017JoingCNNPed.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" href="https://github.com/xiaohuige1/udn_extend" target="_blank">Source code</a>]                        <br>  <br>

<em> Extend our work on modeling deformation for generic object detection. This new deformation handling layer can be placed anywhere. </em>   <br>
									<strong>Wanli Ouyang</strong>, Xingyu Zeng,  Xiaogang Wang, et al,
                      "DeepID-Net: Object Detection with Deformable Part Based Convolutional Neural Networks," 
                      <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, accepted, 2016.
												[<a class="aLink" href="./Papers/DeepID-Net.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Project" href="./projects/ImageNet/index.html" target="_blank">Project</a>]																								<br>  <br>
                          
												
									<em> The first cascade network for generic object detection. </em>   <br>
                      	<strong>Wanli Ouyang</strong>, Kun Wang, Xin Zhu, Xiaogang Wang. "Chained Cascade Network
for Object Detection", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Ouyang_Chained_Cascade_Network_ICCV_2017_paper.pdf" target="_blank">Full Text</a>]  
[<a class="aLink" title="Download source code" href="https://github.com/wk910930/ccnn" target="_blank">Source code</a>]  	
                        <br>  
												<br>
												
<em> A simple and effective multi-scale feature operation. Showing and solving the initialization problem in existing multi-branch networks, e.g. Inception V2-V5, Hourglass, ResNxt, etc. </em>   <br>

												Wei Yang, Shuang Li, <strong>Wanli Ouyang</strong>, Hongsheng Li, XiaogangWang. "Learning Feature Pyramids for Human Pose Estimation", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Yang_Learning_Feature_Pyramids_ICCV_2017_paper.pdf" target="_blank">Full Text</a>] [<a class="aLink" title="Code on Github" href="https://github.com/bearpaw/PyraNet" target="_blank">Source code</a>]
                        <br>  <br>



									<em> The first work on structured feature learning. </em>   <br>
                      	X. Chu,  <strong>Wanli Ouyang</strong> , H. Li, and X. Wang. 
                      	"Structured feature learning for pose estimation",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="http://arxiv.org/pdf/1603.09065.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Project" href="http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html" target="_blank">Project and dataset </a>]                          
                        [<a class="aLink" title="Project" href="https://www.youtube.com/watch?v=SMFt6TJ-ntA" target="_blank">Spotlight talk</a>]                          
                        [<a class="aLink" title="Code" href="https://github.com/chuxiaoselena/StructuredFeature" target="_blank">Source code </a>]                          
                        [<a class="aLink" title="Supplementary" href="http://www.ee.cuhk.edu.hk/~xgwang/StructureFeature/supp.pdf" target="_blank">Supplementary </a>]                          
                          <br>
                        <br>

									<em> The first Fully Convolutional Network for visual tracking. </em> <br>
                      	Lijun Wang,  <strong>Wanli Ouyang</strong>, Xiaogang Wang, and Huchuan Lu,
                      	"Visual Tracking with Fully Convolutional Networks",  In <em>Proc. ICCV </em> 2015. 
                        [<a class="aLink" title="Download Full Text" href="Papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf" target="_blank">Full Text</a>]  
                      [<a class="aLink" title="Project" href="http://scott89.github.io/FCNT/" target="_blank">Project and source code </a>]                

                  
                  
                  
                  
                  
                  
                  
                  
                  
                  <h1>Journal Papers</h1>

                  
                  
                  <table border="0" cellspacing="0" cellpadding="5" width="900">
                    <tbody id="journal_list">

                      




                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/progressive_cross-stream_cooperation_in_spatial_and_temporal_domain_for_action_localization.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Rui Su, Dong Xu, Luping Zhou, and <strong>Ouyang Wanli</strong>, "Progressive Cross-stream Cooperation in Spatial and Temporal Domain for Action Localization"  IEEE Trans. Pattern Anal. Mach. Intell. (<em>PAMI</em>), accepted, May, 2020
                          [<a class="aLink" href="#" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/An_End-to-End Learning_Framework_for_Video_Compression.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Guo Lu, Xiaoyun Zhang, <strong>W. Ouyang</strong>, Li Chen, Zhiyong Gao, Dong Xu, "An End-to-End Learning Framework for Video Compression"  IEEE Trans. Pattern Anal. Mach. Intell. (<em>PAMI</em>), accepted, Apr, 2020
                          [<a class="aLink" href="#" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/Image_Captioning_with_End-to-end_Attribute_Detection_and_Subsequent_Attributes_Prediction.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Yiqing Huang, Jiansheng Chen, <strong>W. Ouyang</strong>, Weitao Wan, Youze Xue, "Image Captioning with End-to-end Attribute Detection and Subsequent Attributes Prediction"  IEEE Trans. Image Process. (<em>TIP</em>) , accepted, Jan, 2020
                          [<a class="aLink" href="#" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/Person_Search_by_Separated_Modeling_and_A_Mask-Guided_Two-Stream_CNN_Model.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          D. Chen, S. Zhang, <strong>W. Ouyang</strong>, J. Yang, Y. Tai, "Person Search by Separated Modeling and A Mask-Guided Two-Stream CNN Model"  IEEE Trans. Image Process. (<em>TIP</em>) , 29: 4669-4682, 2020
                          [<a class="aLink" href="#" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>
                      
                        <tr class="pub_tr_2">
                          <td width="20px" class="pub_td_number">  </td>
                          <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/Self-Paced_Collaborative_and_Adversarial_Network_for_Unsupervised_Domain_Adaptation.png" width="336px" height="200px"> </td>
                          <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                            Weichen Zhang, Dong Xu, <strong>Wanli Ouyang</strong>, W. Li, "Self-Paced Collaborative and Adversarial Network for Unsupervised Domain Adaptation"  IEEE Trans. Pattern Anal. Mach. Intell. (<em>PAMI</em>), accepted, Sept. 2019
                            [<a class="aLink" href="#" target="_blank">Full Text</a>]
                            <br>
                          </td></tr>
										
                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/Det_Survey_2019.JPG" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Liu, Li, <strong>Wanli Ouyang</strong>, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, and Matti Pietikäinen, "Deep learning for generic object detection: A survey,"  <em>IJCV</em>, accepted, Sept. 2019.
                          [<a class="aLink" href="https://arxiv.org/pdf/1809.02165" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/DeepNonLocal.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Guo Lu, Xiaoyun Zhang, <strong>Wanli Ouyang</strong>, Dong Xu, Li Chen, and Zhiyong Gao, “Deep Non-local Kalman Network for Video Compression Artifact Reduction”  <em>TIP</em>, accepted, Sept. 2019.
                          [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Guo_Lu_Deep_Kalman_Filtering_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/ContextualSpatial.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Lingbo Liu, Zhilin Qiu, Guanbin Li, Qing Wang, <strong>Wanli Ouyang</strong>, Liang Lin, “Contextualized Spatial-Temporal Network for Taxi Origin-Destination Demand Prediction”, IEEE Transactions on Intelligent Transportation Systems (TITS), accepted Apr., 2019.
                          [<a class="aLink" href="https://arxiv.org/abs/1905.06335" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>  										
									
												

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/ZoomNet.jpg" width="336px" height="300px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Hongyang Li, Yu Liu, <strong>Wanli Ouyang</strong>, Xiaogang Wang, "Zoom out-and-in network with map attention decision for region proposal and object detection," <em>International Journal of Computer Vision, (IJCV)</em>, Accepted Jun., 2018.                
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2018_IJCV1&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2018_IJCV1&#39;)">BibTeX</a>]
                          [<a class="aLink" href="https://arxiv.org/abs/1709.04347" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>  										
                      
                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/TPAMI18_Depth.jpg" width="336px" height="180px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Dan Xu, Elisa Ricci, <strong>Wanli Ouyang</strong>, Xiaogang Wang, Nicu Sebe, "Monocular Depth Estimation using Multi-Scale Continuous CRFs as Sequential Deep Networks," <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, Accepted Apr., 2018. 
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2018_PAMI1&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2018_PAMI1&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/pami_depth.pdf" target="_blank">Full Text</a>]
                          [<a class="aLink" href="https://github.com/danxuhk/ContinuousCRF-CNN" target="_blank">Source code</a>]
                          
                          
                          <br>
                        </td></tr>  
											

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/DCCRF.jpg" width="336px" height="150px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Hui Zhou, <strong>Wanli Ouyang</strong>, Jian Cheng, Xiaogang Wang, and Hongsheng Li, "Deep Continuous Conditional Random Fields with Asymmetric Inter-object Constraints for Online Multi-object Tracking," <em>IEEE Trans. Circuits and System for Video Technology (CSVT)</em>, Accepted Apr., 2018.                
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2018_CSVT1&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2018_CSVT1&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/DCCRF_CSVT.pdf" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>   

									


                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/GBD_TPAMI.jpg" width="336px" height="155px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Xingyu Zeng (equal contribution), <strong>Wanli Ouyang</strong> (equal contribution), Junjie Yan, Hongsheng Li, Tong Xiao, Kun Wang, Yu Liu, Yucong Zhou, Bin
  Yang, Zhe Wang, Hui Zhou, Xiaogang Wang,
                        "Crafting GBD-Net for Object Detection," 
                        <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, accepted, 2017.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2017_PAMI2&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2017_PAMI2&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/Zeng2017_GBD_PAMI.pdf" target="_blank">Full Text</a>]
                          [<a class="aLink" href="https://github.com/craftGBD/craftGBD" target="_blank"> Code </a>]
                          [<a class="aLink" href="./projects/GBD/index.html" target="_blank">Project page & code </a>]												
                          <br>
                          
                        </td></tr>   



                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/TCNN.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          K. Kang, H. Li, J. Yan, X. Zeng, B. Yang, T. Xiao, C. Zhang, Z. Wang, R. Wang, X. Wang, <strong>W. Ouyang</strong>, T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos, IEEE Transactions on Circuits and Systems for Video Technology (CSVT), accepted, 2017.
                          [<a class="aLink" href="https://arxiv.org/abs/1604.02532" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>


                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <!--<img style="width: 336Px;" alt="Wanli" src="imgs/Deep_IDNet_PAMI.jpg" width="336px" height="155px">--> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          <strong>Wanli Ouyang</strong>, Xingyu Zeng,  Xiaogang Wang, et al,
                        "DeepID-Net: Object Detection with Deformable Part Based Convolutional Neural Networks," 
                        <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, accepted, 2016.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2016_PAMI2&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2016_PAMI2&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/DeepID-Net.pdf" target="_blank">Full Text</a>]
                          [<a class="aLink" title="Project" href="./projects/ImageNet/index.html" target="_blank">Project</a>]                          
                          <br>
                          
                        </td></tr>   

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <!--<img style="width: 336Px;" alt="Wanli" src="images/OHT_J.jpg" width="336px" height="205px">--><img style="width: 336Px;" alt="Wanli" src="imgs/FastFull.png" width="336px" height="205px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          <strong>Wanli Ouyang</strong>, Tianle Zhao, Wai-Kuen Cham,  Liying Wei
                        "Fast Full-Search Equivalent Pattern Matching Using Asymmetric Haar Wavelet Packets," 
                        <em>IEEE Trans. Circuits and System for Video Technology (CSVT)</em>, accepted, 2016.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2016_IJCV&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2016_IJCV&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/AHT_CSVT16.pdf" target="_blank">Full Text</a>]
                          [<a class="aLink" href="./OHT.htm" target="_blank">Project & source code</a>]
                          [<a class="aLink" title="Download Slides" href="./PPT/OHT1.ppt" target="_blank">Slides</a>]
                          <br>
                          
                          
                        </td></tr>   

                        
                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <!--<img style="width: 336Px;" alt="Wanli" src="imgs/LearningMutual.png" width="336px" height="205px">--> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          <strong>Wanli Ouyang</strong>, Xingyu Zeng and Xiaogang Wang, 
                        "Learning Mutual Visibility Relationship for Pedestrian Detection with a Deep Model," 
                        <em>International Journal of Computer Vision (IJCV)</em>, accepted, 2016.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2016_IJCV&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2016_IJCV&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/Mutual-DBN-IJCV16.pdf" target="_blank">Full Text</a>]
                          [<a class="aLink" href="./projects/ouyangZWcvpr13MutVisibility/index.html" target="_blank">  Project and code</a>]
                          <br>
                          
                          
                        </td></tr>   

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <!--<img style="width: 336Px;" alt="Wanli" src="imgs/PersonReid.png" width="336px" height="120px">--> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> Rui Zhao, <strong>Wanli Ouyang</strong> and Xiaogang Wang, 
                        "Person Re-identification by saliency Learning," 
                        <em>IEEE Trans. Pattern Analysis and machine Intelligence(TPAMI)</em>, accepted, 2016.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2016_tpami&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2016_TPAMI&#39;)">BibTeX</a>]
                          [<a class="aLink" href=".\projects\Person_reid_pami\TPAMI2544310_proof2.pdf" target="_blank">  Full Text</a>]
                          [<a class="aLink" href="" target="_blank">  Project and dataset(N/A)</a>]
                          <br>
                          
                          
                        </td></tr>   
                        
                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number"> </td>
                        <td width="304px" style="text-align: center"> <!--<img style="width: 336Px;" alt="Wanli" src="HumanDBNDetRes.jpg" width="336px" height="205px">--> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> <strong>Wanli Ouyang</strong>, Xingyu Zeng and Xiaogang Wang, 
                        "Partial Occlusion Handling in Pedestrian Detection with a Deep Model," 
                        <em>IEEE Trans. Circuits and System for Video Technology (TCSVT)</em>, accepted, 2015.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_tpami&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_TPAMI&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/TCSVT_ouyang_xyZeng_xgwang.pdf" target="_blank">  Full Text</a>]
                          [<a class="aLink" href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_pedestrian.html" target="_blank">  Project</a>]
                          <br>
                          
                          
                        </td></tr>   


                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <!--<img style="width: 336Px;" alt="Wanli" src="imgs/SinglePedestrian.png" width="336px" height="205px">--> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> <strong>Wanli Ouyang</strong>, Xingyu Zeng and Xiaogang Wang, 
                        "Single-Pedestrian Detection Aided by Two-Pedestrian Detection," 
                        <em>IEEE Trans. Pattern Analysis and machine Intelligence(TPAMI)</em>, 37(9), 1875-1889, 2015.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_tpami&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_tip&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/tpami15-ouyang_xgWang_xyZeng.pdf" target="_blank">  Full Text</a>]
                          [<a class="aLink" href="./projects/ouyangWcvpr13MultiPed/index.html" target="_blank">  Project, source code and dataset</a>]
                          <br>
                          
                          
                        </td></tr>   
                        
                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="mainpa1.jpg" width="336px" height="205px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> <strong>Wanli Ouyang</strong>, Renqi Zhang and Wai-Kuen Cham, 
                        "Segmented Gray-Code Kernels for Fast Pattern Matching," 
                        <em>IEEE Trans. Image Processing(TIP)</em>, 22(4):1512-1525, Apr. 2013.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_tip&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_tip&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/SegGCK.pdf" target="_blank">  Full Text</a>]
                          [<a class="aLink" href="./SegGCK.htm" target="_blank">  Project, source code and dataset</a>]
                          <br>
                          
                          
                        </td></tr>   

                      
                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                      <td width="304px" style="text-align: center"> <!--  <img style="width: 336Px;" alt="Wanli" src="mainpa1.jpg" width="336px" height="205px"> </td>  -->                    
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> <strong>Wanli Ouyang</strong>, Federico Tombari, Stefano Mattoccia, Luigi Di Stefano and Wai-Kuen Cham, 
                        "Performance Evaluation of Full Search Equivalent Pattern Matching Algorithms," 
                        <em>IEEE Trans. Pattern Analysis and machine Intelligence(TPAMI)</em>, 34(1):127 - 143, Jan. 2012.
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2012_tpami&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2012_tpami&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/PME_TPAMI.pdf" target="_blank">  Full Text</a>]
                          [<a class="aLink" href="./PMEval/index.htm" target="_blank">  Project, source code, and dataset</a>]
                          <br>
                          
                          
                        </td></tr>   
                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px"> </td> 
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                        F. Tombari, <strong>Wanli Ouyang</strong>, L. Di Stefano, W.K. Cham, 
                        “Adaptive Low Resolution Pruning for Fast Full-Search Equivalent Pattern Matching,”
                        <em>Pattern Recognition Letters (JPRL)</em>, 32(15), pp 2119-2127, November 2011

                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2011_Jprl&#39;)">Abstract</a>]
                          [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2011_Jprl&#39;)">BibTeX</a>]
                          [<a class="aLink" href="./Papers/jprl11b.pdf" target="_blank">  Full Text</a>]
                          <br>
                          
                          
                        </td></tr>                             
                                      
                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number"> </td>
                        <td width="304px"><!-- <img alt="Photo" src="imgs/FastAlgorithm.png" width="336px" height="205px"> </td> -->
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"><strong> Wanli Ouyang </strong> and Wai-Kuen Cham, 
                          "Fast algorithm for Walsh Hadamard transform on sliding windows", 
                          <em> IEEE Trans. Pattern Analysis and machine Intelligence (TPAMI), </em>
                          32(1):165-171, Jan. 2010.                      
                          [<a class="aLink" title="Download Full Text" href="./Papers/Manu_FWHT.pdf" target="_blank">Full Text</a>]
                          <br>
                          
                                                    
                        </td></tr>
                        

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <!--<img style="width: 336Px;" alt="Wanli" src="imgs/ImprovedBoundary.png" width="336px" height="200px">--> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Y. Li, N. Xiao, <strong>W. Ouyang</strong>, ”Improved Boundary Equilibrium Generative Adversarial Networks,” IEEE Access”, Accepted, Jan., 2018.
                          [<a class="aLink" href="https://ieeexplore.ieee.org/document/8288664" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/ImprovedGenerative.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Y. Li, N. Xiao, <strong>W. Ouyang</strong>, ”Improved Generative Adversarial Networks with Reconstruction Loss,” Neurocomputing, Accepted, Oct., 2018.
                          [<a class="aLink" href="https://www.sciencedirect.com/science/article/pii/S0925231218311901" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/PartAligned.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          L. Huang, Y. Huang, <strong>Wanli Ouyang</strong>, L. Wang, ”Part-Aligned Pose-Guided Recurrent Network for Action Recognition,” Pattern Recognition (PR), accepted Mar., 2019.
                          [<a class="aLink" href="https://www.sciencedirect.com/science/article/pii/S0031320319301098" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/PerceptualImage.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Yukai Shi, Jinghui Qin, Pengxu Wei, <strong>Wanli Ouyang</strong>, Liang Lin, “Perceptual Image Enhancement by Relativistic Discriminant Learning With Cross-Scale Aggregated Representation”, IEEE Access, accepted Mar., 2019.
                          [<a class="aLink" href="https://ieeexplore.ieee.org/document/8672893" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number">  </td>
                        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="imgs/ShowTell.png" width="336px" height="200px"> </td>
                        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
                          Zhiwang Zhang, Dong Xu, <strong>Wanli Ouyang</strong>, Chuanqi Tan, “Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization”, IEEE Trans. Circuits Syst. Video Technol. (CSVT), accepted Aug., 2019.
                          [<a class="aLink" href="https://ieeexplore.ieee.org/document/8807239" target="_blank">Full Text</a>]
                          <br>
                        </td></tr>

                      <tr class="pub_tr_1">  
                      <td width="20%" align="left" colspan="2" style="HEIGHT:10px"></td></tr>
                      <tr class="pub_tr_1">  
                      <td width="20%" align="left" colspan="2"><a class="aLink" href="./#Top">Back To Top</a></td></tr>
                    
                    </tbody>
                  </table>

                    
                      	
<!--========================Conference Papers ========================-->                      	
                  <h1>Conference Papers</h1>
                  <table border="0" cellspacing="0" cellpadding="5" width="900">
                    <tbody>
                

                      <tr class="pub_tr_2">
                        <td width="20px" class="pub_td_number"> </td>
                        <td width="304px" style="vertical-align: middle"> <img alt="ecoNAS" border="0" src="imgs/ecoNAS.jpg" width="304px" height="200" >
                        </td>
                    
                        <td class="pub_td_text" width="500px" style="vertical-align: middle"> 
                          <br>
                          Dongzhan Zhou, Xinchi Zhou, Wenwei Zhang, Chen Change Loy, Shuai Yi, Xuesen Zhang, <strong>Wanli Ouyang</strong>, “EcoNAS: Finding Proxies for Economical Neural Architecture Search”, Proc. CVPR, 2020.                  
                          <br>     
                          <br>
                          Ziyu Liu, Hongwen Zhang, Zhenghao Chen, Zhiyong Wang, <strong>W. Ouyang</strong>, “Unifying Spatial-Temporal Graph Convolutions with Disentangled Multi-Scale Aggregators for Skeleton-Based Action Recognition”, CVPR, 2020, accepted (Oral).                
                          <br>
                          <br>
                          Jinyang Guo, <strong>W. Ouyang</strong>, Dong Xu, “Multi-Dimensional Pruning: A Uniﬁed Framework for Model Compression”, CVPR, 2020, accepted (Oral).                 
                          <br> 
                          <br>
                          Xiang Li, Chen Lin, Chuming Li, Ming SUn, Wei Wu, Junjie Yan, <strong>W. Ouyang</strong>, “Improving One-shot NAS by Suppressing the Posterior Fading”, CVPR, 2020, accepted.                 
                          <br> 
                          <br>
                          Jingru Tan, Changbao Wang, Buyu Li, Quanquan Li, <strong>W. Ouyang</strong>, Changqing Yin, Junjie Yan, “Equalization Loss for Long-Tailed Object Recognition, CVPR, 2020, accepted.               
                          <br> 
                          <br>
                          Wang Zeng, Wei Yang, <strong>W. Ouyang</strong>, Ping Luo, Wentao Liu, Xiaogang Wang, “3D Human Mesh Regression with Dense Correspondence”, CVPR, 2020, accepted.                 
                          <br>                         

                        </td>
                    </tr>


                        <tr class="pub_tr_2">
                            <td width="20px" class="pub_td_number"> </td>
                         <td width="304px" style="vertical-align: middle"> 
                        </td>
                        
                            <td class="pub_td_text" width="500px" style="vertical-align: middle"> 
                              <br>                  
                              Jinyang Guo, <strong>Wanli Ouyang</strong>, Dong Xu. ”Channel Pruning Guided by Classiﬁcation Loss and Feature Importance”, Proc. AAAI, 2020. [<a class="aLink" target="_blank">Full Text</a>]
                              <br>     
                              <br>                          
                              Linjiang Huang, Yan Huang, <strong>Wanli Ouyang</strong>, Liang Wang, “Relational Prototypical Network for Weakly Supervised Temporal Action Localization”, Proc. AAAI, 2020, (Oral). [<a class="aLink" target="_blank">Full Text</a>]
                              <br>
                              <br>
                              Linjiang Huang, Yan Huang, <strong>Wanli Ouyang</strong>, Liang Wang, “Part-Level Graph Convolutional Network for Skeleton-Based Action Recognition”, Proc. AAAI, 2020, (Oral).[<a class="aLink" target="_blank">Full Text</a>]
                              <br>
                              <br>
                              Di Chen, Shanshan Zhang, <strong>Wanli Ouyang</strong>, Jian Yang, Bernt Schiele, “Hierarchical Online Instance Matching for Person Search”, Proc. AAAI, 2020, accepted (Oral). [<a class="aLink" target="_blank">Full Text</a>]
                              <br>
                              <br>
                              Qi Chu, <strong>Wanli Ouyang</strong>, Bin Liu, Feng Zhu, Nenghai Yu, “DASOT: A Uniﬁed Framework Integrating Data Association and Single Object Tracking for Online Multi-Object Tracking”, Proc. AAAI, 2020, accepted. [<a class="aLink" target="_blank">Full Text</a>]
                              <br>
                              <br>

                            </td>
                        </tr>



                


                <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"> <img alt="OHT_Complexity" border="0" src="imgs/GradNet.png" width="304px" height="200" ><img alt="OHT_Complexity" border="0" src="imgs/CrowdCounting.png" width="304px" height="70" ><img alt="OHT_Complexity" border="0" src="imgs/AccurateMonocular.png" width="304px" height="70" >
                  </td>
                  
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> 
                        <br>                  
Peixia Li, Boyu Chen, <strong>W. Ouyang</strong>, Dong Wang, Xiaoyun Yang, Huchuan Lu. ”GradNet: Gradient-Guided Network for Visual Object Tracking”, Proc. ICCV, 2019. (Oral) [<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_GradNet_Gradient-Guided_Network_for_Visual_Object_Tracking_ICCV_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>     
                        <br>                          
Haodong Duan, Kwan-Yee Lin, Sheng Jin, Wentao Liu, Chen Qian, <strong>W. Ouyang</strong>. ”TRB: A Novel Triplet Representation for Understanding 2D Human Body”, Proc. ICCV, 2019. (Oral) [<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Duan_TRB_A_Novel_Triplet_Representation_for_Understanding_2D_Human_Body_ICCV_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>    
                        <br>  
                        Lingbo Liu, Zhilin Qiu , Guanbin Li, Shufan Liu, <strong>W. Ouyang</strong>, Liang Lin. ”Crowd Counting with Deep Structured Scale Integration Network”, Proc. ICCV, 2019.  [<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Crowd_Counting_With_Deep_Structured_Scale_Integration_Network_ICCV_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>    
                        <br>                        
                        Lu Sheng, Dan Xu, <strong>W. Ouyang</strong>, Xiaogang Wang. ”Unsupervised Collaborative Learning of Keyframe Detection and Visual Odometry towards Monocular Deep SLAM”, Proc. ICCV, 2019. [<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Sheng_Unsupervised_Collaborative_Learning_of_Keyframe_Detection_and_Visual_Odometry_Towards_ICCV_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>    
                        <br>    
Chen Lin, Minghao Guo, Chuming Li, Xin Yuan, Wei Wu, Junjie Yan, Dahua Lin, <strong>W. Ouyang</strong>. ”Online Hyper-parameter Learning for Auto-Augmentation Strategy”, Proc. ICCV, 2019.[<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Lin_Online_Hyper-Parameter_Learning_for_Auto-Augmentation_Strategy_ICCV_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>    
                        <br>    
Xinzhu Ma, Zhihui Wang, Haojie Li, Pengbo Zhang, <strong>W. Ouyang</strong>, Xin Fan. ”Accurate Monocular Object Detection via Color-Embedded 3D Reconstruction for Autonomous Driving”, Proc. ICCV, 2019. [<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Ma_Accurate_Monocular_3D_Object_Detection_via_Color-Embedded_3D_Reconstruction_for_ICCV_2019_paper.pdf" target="_blank">Full Text</a>] 
                        <br>    
                        <br>    
Yunan Li, Qiguang Miao, <strong>W. Ouyang</strong>, Zhenxin Ma, Huijuan Fang, Chao Dong, Yining Quan. ”LAP-Net: Level-Aware Progressive Network for Image Dehazing”, Proc. ICCV, 2019. [<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Li_LAP-Net_Level-Aware_Progressive_ICCV_2019_supplemental.pdf" target="_blank">Full Text</a>]
                        <br>    
                        <br>    
Chuming Li, Xin Yuan, Chen Lin, Minghao Guo, Wei Wu, Junjie Yan, <strong>W. Ouyang</strong>. ”AM-LFS: AutoML for Loss Function Search”, Proc. ICCV, 2019. [<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_AM-LFS_AutoML_for_Loss_Function_Search_ICCV_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>    
                        <br>    
Yingyue Xu, Dan Xu, Xiaopeng Hong, W. Ouyang, Rongrong Ji, Min Xu, Guoying Zhao. ”Structured Modeling of Joint Deep Feature and Prediction Reﬁnement for Salient Object Detection”, Proc. ICCV, 2019. [<a class="aLink" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Structured_Modeling_of_Joint_Deep_Feature_and_Prediction_Refinement_for_ICCV_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>  
                      </td>
                  </tr>


                <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"> <img alt="OHT_Complexity" border="0" src="imgs/DaNet.png" width="304px" height="150" > <img alt="OHT_Complexity" border="0" src="imgs/IntersectGAN.png" width="304px" height="150" ></td>
 <td class="pub_td_text" width="500px" style="vertical-align: middle">                          <br>                  
                  H. Zhang, Jie Cao, Guo Lu, W. Ouyang, Zhenan Sun. ”DaNet: Decomposeand-aggregate Network for 3D Human Shape and Pose Estimation ”, Proc. ACM Multimedia, 2019. [<a class="aLink" href="https://hongwenzhang.github.io/pdf/acmmm19DaNet.pdf" target="_blank">Full Text</a>] 
                        <br>
                        <br>
                  Z. Yao, B. Zhang, Z. Wang W. Ouyang, D. Xu, D. Feng. ”IntersectGAN: Learning Domain Intersection for Generating Images with Multiple Attributes”, Proc. ACM Multimedia, 2019. [<a class="aLink" href="https://arxiv.org/abs/1909.09767" target="_blank">Full Text</a>] 
                      </td>
                  </tr>  



										
                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"> <img alt="OHT_Complexity" border="0" src="./imgs/DVC.JPG" width="304px" height="200" ><img alt="OHT_Complexity" border="0" src="./imgs/HybridTaskCascade.JPG" width="304px" height="70" ><img alt="OHT_Complexity" border="0" src="./imgs/GS3D.JPG" width="304px" height="70" >
									</td>
									
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">	
                        <br>									
Guo Lu, <strong>Wanli Ouyang</strong>, Dong Xu,  Chunlei Cai, Xiaoyun Zhang, Zhiyong Gao. "DVC: An End-to-end Deep Video Compression Framework", Proc. CVPR, 2019, Accepted. (Oral) [<a class="aLink" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Lu_DVC_An_End-To-End_Deep_Video_Compression_Framework_CVPR_2019_paper.pdf" target="_blank">Full Text</a>] [<a class="aLink" href="https://github.com/GuoLusjtu/DVC" target="_blank">Source code</a>]
                        <br>		 
												<br>													
Kai Chen, Jiangmiao Pang, Jiaqi Wang, Yu Xiong, Xiaoxiao Li, Shuyang Sun, Wansen Feng, Ziwei Liu, Jianping Shi, <strong>Wanli Ouyang</strong>,Chen Change Loy, Dahua Lin. "Hybrid Task Cascade for Instance Segmentation", Proc. CVPR, 2019, Accepted. [<a class="aLink" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Hybrid_Task_Cascade_for_Instance_Segmentation_CVPR_2019_paper.pdf" target="_blank">Full Text</a>]   [<a class="aLink" href="https://github.com/
open-mmlab/mmdetection" target="_blank">Source code (ranking 1st in the COCO 2018 Challenge Object Detection Task) </a>]
                        <br>		
												<br>	
												Buyu Li, <strong>Wanli Ouyang</strong>, Lu Sheng, et. al. "GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving", Proc. CVPR, 2019, Accepted.	[<a class="aLink" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_GS3D_An_Efficient_3D_Object_Detection_Framework_for_Autonomous_Driving_CVPR_2019_paper.pdf" target="_blank">Full Text</a>]
												<br>		
												<br>												
												Jiangmiao Pang, Kai. Chen, Jianping Shi, <strong>Wanli Ouyang</strong>, et. al. "Libra R-CNN: Balanced Learning for Object Detection", Proc. CVPR, 2019, Accepted.	[<a class="aLink" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Pang_Libra_R-CNN_Towards_Balanced_Learning_for_Object_Detection_CVPR_2019_paper.pdf" target="_blank">Full Text</a>]	[<a class="aLink" href="https://github.com/OceanPang/
Libra_R-CNN" target="_blank">Source code</a>]	
                        <br>		
												<br>		
Chunfeng Song, Yan Huang, <strong>Wanli Ouyang</strong>, Liang Wang. "Box-driven Class-wise Region Masking and Filling Rate Guided Loss for Weakly Supervised Semantic Segmentation", Proc. CVPR, 2019, Accepted.  [<a class="aLink" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Song_Box-Driven_Class-Wise_Region_Masking_and_Filling_Rate_Guided_Loss_for_CVPR_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>		
												<br>		
Sheng Jin, Wentao Liu, <strong>Wanli Ouyang</strong>, Chen Qian. "Multi-person Articulated Tracking with Spatial and Temporal Embeddings", Proc. CVPR, 2019, Accepted. [<a class="aLink" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Jin_Multi-Person_Articulated_Tracking_With_Spatial_and_Temporal_Embeddings_CVPR_2019_paper.pdf" target="_blank">Full Text</a>] 
                        <br>		
												<br>		
Rui Su, <strong>Wanli Ouyang</strong>, Luping Zhou, Dong Xu. "Improving Action Localization by Progressive Cross-stream Cooperation", Proc. CVPR, 2019, Accepted.  [<a class="aLink" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Su_Improving_Action_Localization_by_Progressive_Cross-Stream_Cooperation_CVPR_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>		
												<br>		
Pu Zhang, <strong>Wanli Ouyang</strong>, Pengfei Zhang, Jianru Xue, Nanning Zheng. "SR-LSTM: State Refinement for LSTM towards Pedestrian Trajectory Prediction", Proc. CVPR, 2019, Accepted. [<a class="aLink" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_SR-LSTM_State_Refinement_for_LSTM_Towards_Pedestrian_Trajectory_Prediction_CVPR_2019_paper.pdf" target="_blank">Full Text</a>]
                        <br>
											  <br>	
								      </td>
									</tr>       
									

                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"> <img alt="OHT_Complexity" border="0" src="./imgs/Intertwiner.JPG" width="304px" height="150" > </td>
 <td class="pub_td_text" width="500px" style="vertical-align: middle">	                        <br>									
									Li, Hongyang, Bo Dai, Shaoshuai Shi, <strong>Wanli Ouyang</strong>, and Xiaogang Wang. "Feature Intertwiner for Object Detection." ICLR, 2019. [<a class="aLink" href="https://openreview.net/pdf?id=SyxZJn05YX" target="_blank">Full Text</a>]   [<a class="aLink" href="https://github.com/hli2020/feature intertwiner" target="_blank">Source code</a>] [<a class="aLink" href="https://docs.google.com/presentation/d/12Syg5OXD6nGwtG_nwmoQ4kqX5GtJ-5pJ1OuVY53FqB0/edit?usp=sharing" target="_blank"> Slides (50-min talk presented at GTC 2019) </a>]  
                        <br>
											  <br>	
								      </td>
									</tr>       
									



                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"><img alt="OHT_Complexity" border="0" src="./imgs/FishNet.jpg" width="304px" height="160" >
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">
											
											  <br>
									Shuyang Sun, Jiangmiao Pang, Jianping Shi, Shuai Yi, <strong>Wanli Ouyang</strong>, "FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction,"  <em>NuerIPS. (Previously called NIPS)</em>, 2018.
												[<a class="aLink" href="http://papers.nips.cc/paper/7356-fishnet-a-versatile-backbone-for-image-region-and-pixel-level-prediction.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" href="https://github.com/kevin-ssy/FishNet" target="_blank"> Source code </a>]  
                        <br>  <br>
								      </td>
									</tr>       


												
                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"> <img alt="OHT_Complexity" border="0" src="./imgs/Encapsule.jpg" width="304px" height="100" ><img alt="OHT_Complexity" border="0" src="./imgs/FactorizableNet.jpg" width="304px" height="200" >
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">												
Hongyang Li, Bo Dai, <strong>Wanli Ouyang</strong>, Xiaoyang Guo, Xiaogang Wang. "Neural
Network Encapsulation ", <em>Proc. ECCV</em>, 2018.[<a class="aLink" title="Download Code" href=" https://github.com/hli2020/nn_capsulation" target="_blank">Code link</a>] [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Hongyang_Li_Neural_Network_Encapsulation_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>		
												<br>
Yi Wei, Xinyu Pan, Hongwei Qin, Junjie Yan, <strong>Wanli Ouyang</strong>, "Quantization
Mimic: Towards Very Tiny CNN for Object Detection". <em>Proc. ECCV</em>, 2018. [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yi_Wei_Quantization_Mimic_Towards_ECCV_2018_paper.pdf" target="_blank">Full Text</a>] 
                        <br>
											  <br>
Yikang Li, <strong>Wanli Ouyang</strong>, Bolei Zhou, Yanwen Cui, Jianping Shi, Chao Zhang, Xiaogang Wang. "Factorizable Net: An Efficient Subgraph-based Framework for
Scene Graph Generation" <em>Proc. ECCV</em>, 2018. [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yikang_LI_Factorizable_Net_An_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
[<a class="aLink" title="Download Code" href="https://github.com/yikang-li/FactorizableNet" target="_blank">Source code</a>]
                        <br>																				
                        <br>
Guo Lu, <strong>Wanli Ouyang</strong>, Dong Xu, Xiaoyun Zhang, Zhiyong Gao, Ming-Ting Sun, "Deep Kalman Filtering Network for Video Compression Artifact Reduction". <em>Proc. ECCV</em>, 2018.  [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Guo_Lu_Deep_Kalman_Filtering_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
											  <br>
Dongang Wang, <strong>Wanli Ouyang</strong>, Wen Li, Dong Xu, "Dividing and Aggregating
Network for Multi-view Action Recognition", <em>Proc. ECCV</em>, 2018.  [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Dongang_Wang_Dividing_and_Aggregating_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
											  <br>
Di Chen, Shanshan Zhang, <strong>Wanli Ouyang</strong>, Jian Yang, Ying Tai, "Person Search
via A Mask-guided Two-stream CNN Model". <em>Proc. ECCV</em>, 2018.  [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Di_Chen_Person_Search_via_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
																		
								      </td>
									</tr>       
									
											
                  <tr class="pub_tr_2">
                     <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"> <img alt="OHT_Complexity" border="0" src="./imgs/OFF.jpg" width="304px" height="200" ></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">  
											
                      	Xuanyi Dong, Yan Yan, <strong>Wanli Ouyang </strong>, Yi Yang. "Style Aggregated Network for Facial Landmark Detection", <em>Proc. CVPR</em>, 2018.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Style_Aggregated_Network_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Yikang Li, Nan Duan, Bolei Zhou, Xiao Chu, <strong>Wanli Ouyang</strong>, Xiaogang Wang. "Visual Question Generation as Dual Task of Visual Question Answering", <em>Proc. CVPR</em>, 2018 (spotlight).
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Visual_Question_Generation_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" title="Download Code" href="https://github.com/yikang-li/iQAN" target="_blank">Source code</a>]
                        <br>
                        <br>
                      	Jing Xu, Rui Zhao, Feng Zhu, Huaming Wang, <strong>Wanli Ouyang</strong>. "Attention-aware Compositional Network for Person Re-Identification", <em>Proc. CVPR</em>, 2018. [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Attention-Aware_Compositional_Network_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Yu Wu, Yutian Lin, Xuanyi Dong, Yan Yan, <strong>Wanli Ouyang</strong>, Yi Yang. "Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning", <em>Proc. CVPR</em>, 2018.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Exploit_the_Unknown_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Wei Yang, <strong>Wanli Ouyang</strong>, Xiaolong Wang, Xiaogang Wang. "3D Human Pose Estimation in the Wild by Adversarial Learning", <em>Proc. CVPR</em>, 2018.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_3D_Human_Pose_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Watch Video on Youtube" href="https://youtu.be/LAxVl4zQT-A" target="_blank">Video</a>]
												<br>
                        <br>
                      	Weichen Zhang, <strong>Wanli Ouyang</strong>, Dong Xu, Wen Li. "Collaborative and Adversarial Network for Unsupervised domain adaptation", <em>Proc. CVPR</em>, 2018. (Spotlight) [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Collaborative_and_Adversarial_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Shuyang Sun, Zhanghui Kuang, Lu Sheng, <strong>Wanli Ouyang</strong>, Wei Zhang. "Optical Flow Guided Feature: A Motion Representation for Video Action Recognition", <em>Proc. CVPR</em>, 2018.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Optical_Flow_Guided_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]												[<a class="aLink" title="Download Source code" href="https://github.com/kevin-ssy/Optical-Flow-Guided-Feature" target="_blank">Source code</a>]                         
												<br>
                        <br>
                      	Dan Xu, <strong>Wanli Ouyang</strong>, Xiaogang Wang, Nicu Sebe. "PAD-Net: Multi-Tasks Guided Prediciton-and-Distillation Network for Simultaneous Depth Estimation and Scene Parsing", <em>Proc. CVPR</em>, 2018.
												[<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.pdf" target="_blank">Full Text</a>] 
                        <br>
                        <br>
                      	Chunfeng Song, Yan Huang, Liang Wang, <strong>Wanli Ouyang</strong>. "Mask-guided Contrastive Attention Model for Person Re-Identification ", <em>Proc. CVPR</em>, 2018. 
												[<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_Mask-Guided_Contrastive_Attention_CVPR_2018_paper.pdf" target="_blank">Full Text</a>] 
[<a class="aLink" title="Download Code" href="https://github.com/developfeng/MGCAM" target="_blank">Source Code</a>]
                        <br>
                        <br>
                      	Lingbo Liu, HongjunWang, Guanbin Li, <strong>Wanli Ouyang</strong>, Liang Lin, "Crowd Counting using Deep Recurrent Spatial-Aware Network", <em>Proc. IJCAI</em>, 2018. [<a class="aLink" title="Download Full Text" href="https://www.ijcai.org/proceedings/2018/0118.pdf" target="_blank">Full Text</a>] 
								    </td>       
                 </tr>       



                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px"> <img alt="OHT_Complexity" border="0" src="./images/ChainCNN.JPG" width="304px" height="240">
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	<strong>Wanli Ouyang</strong>, Kun Wang, Xin Zhu, Xiaogang Wang. "Chained Cascade Network
for Object Detection", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Ouyang_Chained_Cascade_Network_ICCV_2017_paper.pdf" target="_blank">Full Text</a>] [<a class="aLink" title="Download source code" href="https://github.com/wk910930/ccnn" target="_blank">Source code</a>]  	
                        <br>
                        <br>
                      	Wei Yang, Shuang Li, <strong>Wanli Ouyang</strong>, Hongsheng Li, XiaogangWang. "Learning Feature Pyramids for Human Pose Estimation", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Yang_Learning_Feature_Pyramids_ICCV_2017_paper.pdf" target="_blank">Full Text</a>] [<a class="aLink" title="Code on Github" href="https://github.com/bearpaw/PyraNet" target="_blank">Code</a>]
                        <br>
                        <br>
                      	Yikang Li, <strong>Wanli Ouyang</strong>, Bolei Zhou, Kun Wang, Xiaogang Wang. "Scene
Graph Generation from Objects, Phrases and Region Captions", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Scene_Graph_Generation_ICCV_2017_paper.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" title="Download Code" href="https://github.com/yikang-li/MSDN" target="_blank">Source code</a>]												
												<br>
                        <br>
                      	Qi Chu, <strong>Wanli Ouyang</strong>, Hongsheng Li, Xiaogang Wang, Bin Liu, Nenghai
Yu. "Online Multi-Object Tracking Using CNN-based Single Object Tracker with
Spatial-Temporal Attention Mechanism", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Chu_Online_Multi-Object_Tracking_ICCV_2017_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Dan Xu, <strong>Wanli Ouyang</strong>, Xavier Alameda-Pineda, Elisa Ricci, Xiaogang Wang,
Nicu Sebe. "Learning Deep Structured Multi-Scale Features using Attention-Gated
CRFs for Contour Prediction", <em>Proc. NIPS</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://papers.nips.cc/paper/6985-learning-deep-structured-multi-scale-features-using-attention-gated-crfs-for-contour-prediction.pdf" target="_blank">Full Text</a>]
                       
                 </tr>       




                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px"> <img alt="OHT_Complexity" border="0" src="./images/vip-cnn.jpg" width="304px" height="350">
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	Kai Kang, Hongsheng Li, <strong> W. Ouyang </strong>, Junjie  Yan, Xihui  Liu, Tong  Xiao, Xiaogang  Wang. ”Object Detection in Vidoes with Tubelet Proposal Networks”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/abs/1702.06355" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Feng  Zhu, Hongsheng Li, <strong> W. Ouyang </strong>, Nenghai  Yu, Xiaogang  Wang. ”Learning Spatial Regularization with Image-level Supervisions for Multi-label Image Classification”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/pdf/1702.05891" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Yu Liu, Junjie  Yan, <strong> W. Ouyang </strong>. ”Quality Aware Network for Set to Set Recognition”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/pdf/1704.03373" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Yikang  LI , <strong> W. Ouyang </strong>, Xiaogang  Wang. ”ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/pdf/1702.07191" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Xiao  Chu, Wei  Yang, <strong> W. Ouyang </strong>, Xiaogang  Wang, Alan  Yuille. ”Multi-Context Attention for Human Pose Estimation”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/pdf/1702.07432" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Download Source code" href="https://github.com/bearpaw/pose-attention" target="_blank">Code</a>]                        
                        
                        <br>
                        <br>
                      	Dan  Xu, Elisa  Ricci, <strong> W. Ouyang </strong>, Xiaogang  Wang, Nicu Sebe. Multi-Scale Continuous CRFs as Sequential Deep Networks for Monocular Depth Estimation”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/abs/1704.02157" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Download Source code" href="https://github.com/danxuhk/ContinuousCRF-CNN" target="_blank">Code</a>]                        
                        [<a class="aLink" title="Presentation" href="https://youtu.be/4mdqh6YGhgE" target="_blank">Presentation</a>]                              <br>
                        <br>
                      	Dan  Xu,  <strong> W. Ouyang </strong>,  Elisa  Ricci, Xiaogang  Wang, Nicu Sebe. Learning Cross-Modal Deep Representations for Robust Pedestrian Detection”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/abs/1704.02431" target="_blank">Full Text</a>]

                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="./images/CRF_CNN.jpg" width="304px" height="65"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	X. Chu, <strong> W. Ouyang </strong>, H. Li, X. Wang. ”CRF-CNN: Modeling Structured Information in Human Pose Estimation”,<em> Advances In Neural Information Processing Systems (NIPS)</em>, 2016.
                        [<a class="aLink" title="Download Full Text" href="./Papers/CRF-CNN_NIPS16" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Download Demo Results" href="http://www.ee.cuhk.edu.hk/~xchu/files/nips_2016_supp.pdf" target="_blank">Demo Results</a>]
                      </td>
                 </tr>       


                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="./projects/GBD/images/motivation.jpg" width="304px" height="200"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	Xingyu Zeng, <strong>Wanli Ouyang</strong>, Bin Yang, Junjie Yan, Xiaogang
                      	"Gated Bidirectional CNN for Object Detection",  In <em>Proc. ECCV </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/GBD.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Z. Wang, H. Li, <strong>W. Ouyang </strong>, X. Wang Wanli
                      	"Learnable Histogram: Statistical Context Features for Deep Neural Networks",  In <em>Proc. ECCV </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/HistDNN.pdf" target="_blank">Full Text</a>]
                        
                    </td>
                 </tr>       
                        
                      	
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/ImageNetFactors.jpg" width="304px" height="200"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	<strong>Wanli Ouyang</strong>, X. Wang, C. Zhang, and X. Yang.
                      	"Factors in finetuning deep model for object detection with long-tail distribution",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/OuyangFactors_CVPR16.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Wei Yang, <strong>Wanli Ouyang</strong>, Hongsheng Li and Xiaogang Wang
                      	"End-to-End Learning of Deformable Mixture of Parts and Deep Convolutional Neural Networks for Human Pose Estimation",  In <em>Proc. CVPR </em> 2016 (Oral). 
                        [<a class="aLink" title=" Download Full Text" href="http://www.ee.cuhk.edu.hk/~xgwang/papers/yangOLWcvpr16.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title=" Project" href="http://www.ee.cuhk.edu.hk/~wyang/Deep-Deformable-Mixture-of-Parts-for-Human-Pose-Estimation/" target="_blank">Project</a>]
												[<a class="aLink" title="Download Source Code" href="https://github.com/bearpaw/eval_pose" target="_blank">Source Code</a>]
												
												
                        <br>
                        <br>
                      	Lijun Wang, <strong>Wanli Ouyang</strong>, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu.
                      	"STCT: Sequentially Training Convolutional Networks for Visual Tracking",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/WangLJ_CVPR16.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	K. Kang, <strong>Wanli Ouyang</strong>, H. Li, and X. Wang.
                      	"Object detection from video tubelets with convolutional neural networks",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/KangVideoDet_CVPR16.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	X. Chu,  <strong>Wanli Ouyang</strong> , H. Li, and X. Wang. 
                      	"Structured feature learning for pose estimation",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="http://arxiv.org/pdf/1603.09065.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Project" href="http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html" target="_blank">Project and dataset </a>]                          
                        [<a class="aLink" title="Project" href="https://www.youtube.com/watch?v=SMFt6TJ-ntA" target="_blank">Spotlight talk</a>]                          
                        [<a class="aLink" title="Code" href="https://github.com/chuxiaoselena/StructuredFeature" target="_blank">Source code </a>]                          
                        [<a class="aLink" title="Supplementary" href="http://www.ee.cuhk.edu.hk/~xgwang/StructureFeature/supp.pdf" target="_blank">Supplementary </a>]                          
                          <br>
                        <br>
                      	Tong Xiao, Hongsheng Li, <strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Learning Deep Feature Representations with Domain Guided Dropout for Person Re-identification",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Full Text on Arxiv" href="http://arxiv.org/abs/1604.07528" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Hongyang Li, <strong>Wanli Ouyang</strong>, Xiaogang Wang
                      	"Multiple Bias on Non-linearity Activation in Deep Neural Networks",  In <em>Proc. ICML </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./MBA_icml16.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Slides" href="http://www.ee.cuhk.edu.hk/~yangli/icml16_bias.pdf" target="_blank">Slides </a>]                          
                        [<a class="aLink" title="Code" href="https://github.com/hli2020/caffe/tree/bias" target="_blank">Code on Github </a>]                          
                      	
                    </td>
                 </tr>       



                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="projects/ImageNetAttribute/dataset.png" width="304px" height="120"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	<strong>Wanli Ouyang</strong>, Hongyang Li, Xingyu Zeng, and Xiaogang Wang,
                      	"Learning Deep Representation with Large-scale Attributes",  In <em>Proc. ICCV </em> 2015. 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_ICCV&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_ICCV&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="./Papers/ImageNetAttributes_ICCV15.pdf" target="_blank">Full Text</a>]  
                        [<a class="aLink" title="Project" href="./projects/ImageNetAttribute/iccv15.html" target="_blank">Project and dataset </a>]                          
                        <br>
                        
                        
                        </td></tr>                        
               
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/Immediacy.PNG" width="304px" height="150"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	Xiao Chu, <strong>Wanli Ouyang</strong>, Wei Yang, and Xiaogang Wang,
                      	"Multi-task Recurrent Neural Network for Immediacy Prediction",  In <em>Proc. ICCV </em> 2015.<strong> (Oral) </strong>
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_ICCVXchu&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_ICCVXchu&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="./Papers/Chu_Multi-Task_Recurrent_Neural_ICCV_2015_paper.pdf" target="_blank">Full Text</a>]  
                        [<a class="aLink" title="Project" href="http://www.ee.cuhk.edu.hk/~xgwang/projectpage_immediacy.html" target="_blank">Project and dataset </a>]                          
                        [<a class="aLink" title="Oral" href="http://videolectures.net/iccv2015_chu_neural_network/" target="_blank">Oral presentation on videolectures</a>]                          
                        [<a class="aLink" title="Poster" href="http://www.ee.cuhk.edu.hk/~xchu/files/iccv_2015_poster.pdf" target="_blank">Poster</a>]                          
                        <br>
                        
                        
</td></tr>                        
             

                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/Tracking_ICCV15.png" width="304px" height="150"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	Lijun Wang,  <strong>Wanli Ouyang</strong>, Xiaogang Wang, and Huchuan Lu,
                      	"Visual Tracking with Fully Convolutional Networks",  In <em>Proc. ICCV </em> 2015. 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_ICCVWang&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_ICCVWang&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="Papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf" target="_blank">Full Text</a>]  
                      [<a class="aLink" title="Project" href="http://scott89.github.io/FCNT/" target="_blank">Project and source code </a>]                
                        <br>
                        
                        
</td></tr>                        

                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/overview_DeepID.png" width="304px" height="120"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <strong>Details that show how our team achieve #2 in the ImageNet Large Scale Visual Recognition Challenge 2014: </strong> <br>
                      	<strong>Wanli Ouyang</strong>, Xiaogang Wang, Xingyu Zeng, Shi Qiu, Ping Luo, Yonglong Tian, Hongsheng Li, Shuo Yang, Zhe Wang, Chen-Change Loy and Xiaoou Tang,
                      	"DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection",  In <em>Proc. CVPR </em> 2015. 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_CVPR1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_CVPR1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="./Papers/DeepIDNet_CVPR15.pdf" target="_blank">Full Text</a>]  
                        [<a class="aLink" title="Project" href="./projects/ImageNet/index.html" target="_blank">Project</a>]                          
                        <br>
                        
                        
                        </td></tr>                        
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/ZhaoCVPR15.JPG" width="304px" height="120"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">  <br>
                      	Rui Zhao, <strong>Wanli Ouyang</strong>,  Hongsheng Li, and Xiaogang Wang,
                      	"Saliency Detection by Multi-context Deep Learning",  In <em>Proc. CVPR </em> 2015. 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_CVPR2&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_CVPR2&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~rzhao/project/deepsal_cvpr15/zhaoOLWcvpr15.pdf" target="_blank">Full Text</a>]  
                        [<a class="aLink" title="Code" href="https://github.com/Robert0812/deepsaldet" target="_blank">Code</a>]                          
                        [<a class="aLink" title="Supplementary Material" href="http://www.ee.cuhk.edu.hk/~rzhao/project/deepsal_cvpr15/zhaoOLWcvpr15.html" target="_blank">Supplementary Material</a>]                          
                        <br>
                                                
                         
                        </td></tr>                        
                        
                                               
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <!--<img alt="OHT_Complexity" border="0" src="imgs/ZengECCV14.jpg" width="304px" height="256px">--></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">Xinyu Zeng, <strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Deep Learning of Scene-Specific Classifier for Pedestrian Detection", In <em>Proc. ECCV </em> 2014.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="http://link.springer.com/chapter/10.1007/978-3-319-10578-9_31" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                                            	
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/PoseDBN.PNG" width="304px" height="256px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Xiao Chu, Xiaogang Wang, 
                      	"Multi-source Deep Learning for Human Pose Estimation", In <em>Proc. IEEE CVPR </em> 2014.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~xgwang/papers/ouyangCWcvpr14.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/ZhaoCVPR14.JPG" width="304px" height="180px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> Rui Zhao,  <strong>Wanli Ouyang</strong>, and Xiaogang Wang, 
                      	"Learning Mid-level Filters for Person Re-Identfiation", In <em>Proc. IEEE CVPR </em> 2014.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2014_CVPR2&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2014_CVPR2&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project page" href="http://www.ee.cuhk.edu.hk/~rzhao/project/midfilter_cvpr14/zhaoOWcvpr14.html" target="_blank">Project</a>]  
                        [<a class="aLink" title="Download Code" href="https://github.com/Robert0812/midfilter_reid" target="_blank">Code</a>]  
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~rzhao/project/midfilter_cvpr14/zhaoOWcvpr14.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>

                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/jointdeep.PNG" width="304px" height="256px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Joint Deep Learning for Pedestrian Detection ", In <em>Proc. IEEE ICCV </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="./projects/ouyangWiccv13Joint/index.html" target="_blank">Project & Source code</a>]  
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~xgwang/papers/ouyangWiccv13.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <!--<img alt="OHT_Complexity" border="0" src="imgs/cascade.PNG" width="304px" height="256px">--></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> Xingyu Zeng, <strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Multi-Stage Contextual Deep Learning for Pedestrian Detection ", In <em>Proc. IEEE ICCV </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV2&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV2&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="" target="_blank">Project </a>]  
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~xgwang/papers/zengOWiccv13.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <!--<img alt="OHT_Complexity" border="0" src="imgs/pedestrian_salience2.PNG" width="304px" height="256px">--></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> Rui Zhao, <strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Person Re-identification by Salience Matching ", In <em>Proc. IEEE ICCV </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV3&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV3&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="" target="_blank">Project</a>]  
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~rzhao/papers/zhaoOWiccv13.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                                                
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="two_pedestrian.PNG" width="304px" height="156px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Single-Pedestrian Detection aided by Multi-pedestrian Detection ", In <em>Proc. IEEE CVPR </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_CVPR1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_CVPR1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="./projects/ouyangWcvpr13MultiPed/index.html" target="_blank">Project & Source code</a>]  
                        [<a class="aLink" title="Download Full Text" href="./Papers/Ouyang2013MultiPed.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="mutual_visibility.PNG" width="304px" height="206px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Xingyu Zeng and Xiaogang Wang, 
                      	"Modeling Mutual Visibility Relationship in Pedestrian Detection ", In <em>Proc. IEEE CVPR </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_CVPR2&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_CVPR2&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="./projects/ouyangZWcvpr13MutVisibility/index.html" target="_blank">Project</a>]  
                        [<a class="aLink" title="Download Full Text" href="./Papers/Ouyang2013MutualDBN.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>

                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="pedestrian_salience.PNG" width="304px" height="256px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> Rui Zhao <strong>Wanli Ouyang</strong>, and Xiaogang Wang, 
                      	"Unsupervised Salience Learning for Person Re-identification ", In <em>Proc. IEEE CVPR </em> 2013.
                        [<a class="aLink" title="Project webpage" href="http://mmlab.ie.cuhk.edu.hk/projects/project_salience_reid/index.html" target="_blank">Project & source code</a>]  
                        [<a class="aLink" title="Download Full Text" href="./Papers/ZhaoCVPR2013Salience.pdf" target="_blank">PDF</a>]  
                        </code></div>
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <!--<img border="0" alt="HumanDBNDetRes" src="HumanDBNDetRes.jpg" width="304px" height="200px">--> </td>
                      <td class="pub_td_text"  width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong> and Xiaogang Wang, 
                      	"A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling," 
                      	In <em>Proc. IEEE CVPR </em> 2012.                      	
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2012_CVPR&#39;)">Abstract</a>]
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2012_CVPR&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="./projects/ouyangWcvpr12Occ/index.html" target="_blank">Project</a>]  
			[<a class="aLink" href="./Papers/CDBN-Ped12.pdf" target="_blank">  Full Text</a>]
			[<a class="aLink" href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_pedestrian.html" target="_blank">CUHK Occlusion Dataset</a>]
<!--                          [<a class="aLink" title="Download Poster" href="./2009_icip_poster.pdf" target="_blank">Poster</a>]
                        [<a class="aLink" title="Download Full Text" href="./2009_icip.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Download Errata" href="./2009_icip_errata.pdf" target="_blank">Errata</a>]     
-->                        <br>
                        
                        
                        </td></tr>
                                                                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="mainpa9.gif" width="304px" height="206px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Renqi Zhang and Wai-Kuen Cham, 
                      	"Fast pattern matching using orthogonal Haar transform ", In <em>Proc. IEEE CVPR </em> 2010.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2011_iscas&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2011_iscas&#39;)">BibTeX</a>]
			[<a class="aLink" href="./OHT.htm" target="_blank">Project & source code</a>]
                        [<a class="aLink" title="Download Slides" href="./PPT/OHT1.ppt" target="_blank">Slides</a>]
                        [<a class="aLink" title="Download Full Text" href="./Papers/Manu_OHT.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img border="0" alt="Img_coded" src="mainpa12.jpg" width="147px" height="161px"><img border="0"  alt="Img_filtered" src="mainpa13.jpg" width="147px" height="161px"> </td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">Renqi Zhang, <strong>Wanli Ouyang</strong> and Wai-Kuen Cham, 
                      	"Image Deblocking using Dual Adaptive FIR Wiener Filter in the DCT Transform Domain," 
                      	<em>In Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing</em>, ICASSP 2009, 
                      	Taiwan, April 19-24, 2009, pp.1181-1184.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2009_icip&#39;)">Abstract</a>]
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2009_icip&#39;)">BibTeX</a>]
<!--                        [<a class="aLink" title="Download Errata" href="./2009_icip_errata.pdf" target="_blank">Errata</a>]     
-->                        <br>
                        
                        
                        </td></tr>
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img border="0" alt="Img_ori" src="mainpa14.jpg" width="100px" height="101px"><img border="0"  alt="Img_canny" src="mainpa15.gif" width="100px" height="101px"> <img border="0"  alt="Img_our3DEdge" src="mainpa16.gif" width="100px" height="101px">  </td>
                      <td class="pub_td_text">Renqi Zhang, <strong>Wanli Ouyang</strong> and Wai-Kuen Cham, 
                      	"Image Multi-scale Edge Detection using 3-D Hidden Markov Model based on the Non-decimated Wavelet," 
                      	In <em> Proc. 2009 IEEE International Conference on Image Processing</em> (ICIP), 
                      	Cairo, Egypt, November 7-10, 2009, pp.2173-2176.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2007_iscas&#39;)">Abstract</a>]
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2007_iscas&#39;)">BibTeX</a>]
<!--                        [<a class="aLink" title="Download Slides" href="./2007_iscas_lecture.pdf" target="_blank">Slides</a>]
                        [<a class="aLink" title="Download Full Text" href="./2007_iscas.pdf" target="_blank">Full Text</a>] -->
                        <br>
                        
                        
                        </td></tr>
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
		      <td width="304px"> </td> 
                      <td class="pub_td_text"> <strong>Wanli Ouyang</strong>, D. Song, C. Xiao, and W. Ju. 
                      	The matrix decomposition representation of DCT algorithms. 
                      	In <em>IEEE midwest sym. Circuits and Syst.</em> (MWCAS), 2005.
                        <br>            
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
		      <td width="304px"> </td> 
                      <td class="pub_td_text"> <strong>Wanli Ouyang</strong>, C. Xiao, W. Ju, and D. Song. The dynamic range acquisition of DCT and IDCT algorithms. 
                      	In <em>IEEE midwest sym. Circuits and Syst. </em> (MWCAS), 2005.
                        <br>            
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
		      <td width="304px"> </td> 
                      <td class="pub_td_text"> <strong>Wanli Ouyang</strong>, C. Xiao, W. Ju, and D. Song. Practical fast asymmetric DCT algorithm based on SIMD and VLIW. 
                      	In <em>IEEE Int. Sym. Intelligent Signal Processing </em>, 2005.
                        <br>            
                        
                    <tr class="pub_tr_1">  
                      <td width="20%" align="left" colspan="2" style="HEIGHT:10px"></td></tr>
                    <tr class="pub_tr_1">  
                      <td width="20%" align="left" colspan="2"><a class="aLink" href="./#Top">Back To Top</a></td></tr>
                    </tbody></table>
</div>
                    
</td></tr></tbody></table>
<!--================================End of Body of Windows Body====================================-->
<!--================================Begin of Footer of Windows Body====================================-->
      <center>
      <table border="0" cellspacing="0" cellpadding="0" width="900px" style="BACKGROUND-IMAGE: url(footer_bg.jpg); COLOR: #2b547e">
        <tbody>
        <tr style="VERTICAL-ALIGN: middle">
<!--          <td style="TEXT-ALIGN: right; WIDTH: 200px; HEIGHT: 30px">
          <img alt="AVSX.org" src="avsx_logo_small.gif"></td> -->
          <td class="i_td_windows_footer">
          Last Update: Apr. 2013. Copyright © 2013-. 
          <a href="http://validator.w3.org/check?uri=./saved_resource.htm">
          <img style="BORDER-BOTTOM: 0px; BORDER-LEFT: 0px; WIDTH: 45px; HEIGHT: 15px; BORDER-TOP: 0px; BORDER-RIGHT: 0px" alt="Valid HTML 4.01 Transitional" src="valid-html401-blue.png"></a> 
          <a href="http://jigsaw.w3.org/css-validator/validator?uri=./saved_resource.htm">
          <img style="BORDER-BOTTOM: 0px; BORDER-LEFT: 0px; WIDTH: 45px; HEIGHT: 15px; BORDER-TOP: 0px; BORDER-RIGHT: 0px" alt="Valid CSS!" src="valid-css-blue.png"></a>
            </td>
        </tr>
        </tbody>
      </table>
      </center>
<!--================================End of Footer of Windows Body====================================-->
	  </center>
    </td>
  </tr>
  </tbody>
</table>


  <script>
    "use strict"


    function readTextFile(file, callback) {
      var rawFile = new XMLHttpRequest();
      rawFile.overrideMimeType("application/json");
      rawFile.open("GET", file, false); //fase for synchronous requests
      rawFile.onreadystatechange = function() {
          if (rawFile.readyState === 4 && rawFile.status == "200") {
            callback(rawFile.responseText);
          }
      }
      rawFile.send(null);
    }
    let journal_data
    readTextFile('https://raw.githubusercontent.com/wlouyang/wlouyang.github.io/master/data.json', function(text){
      journal_data = JSON.parse(text);
      console.log(journal_data);
    });


    function pubItemConstructor(pubitem) {
      let obj;
      obj = document.createElement('template');
      let html_template = `
        <tr class="pub_tr_2">
        <td width="20px" class="pub_td_number">  </td>
        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="IMAGE" width="336px" height="200px"> </td>
        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
        AUTHORS, "TITLE"  JOURNAL
          [<a class="aLink" href="#" target="_blank">Full Text</a>]
          <br>
        </td></tr>
      `;
      obj.innerHTML = html_template
      .replace("AUTHORS", pubitem.authors)
      .replace("TITLE", pubitem.title)
      .replace("JOURNAL", pubitem.journal)
      .replace("IMAGE", pubitem.image);

      return obj.content.firstElementChild;
    }

    journal_list = document.getElementById("journal_list");

    let pubitem
    for (pubitem of journal_data.journals) {
      journal_list.append(pubItemConstructor(pubitem))
    }



  </script>



</body></html>