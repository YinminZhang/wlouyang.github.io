 <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- saved from url=(0022)https://wlouyang.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Wanli Ouyang - Homepage</title>

<!--- <link rel="shortcut icon" type="image/ico" href="http://www.interdigital.com/idsystem/favicon.ico"><link rel="stylesheet" type="text/css" href="style.css" media="screen"> -->
 <script type="text/javascript" src="jsript.js"></script>  

<style type="text/css">@import url( style.css );
DIV.b-mobile {
	DISPLAY: none
}
</style>

<meta name="GENERATOR" content="MSHTML 8.00.6001.18852">
</head>

<body style="VERTICAL-ALIGN: middle">
<table border="0" cellspacing="0" cellpadding="0" width="100%">
  <tbody>
  <tr>
    <td><a name="Top"></a>
      <center>
      <!--================================Begin of Header of Windows Body====================================-->
      <table style="BACKGROUND-IMAGE: url(wave.jpg); BACKGROUND-REPEAT: no-repeat;BACKGROUND-POSITION:center" border="0" cellspacing="0" cellpadding="0" width="100%">
        <tbody>
        <tr>
          <td>
            <center>
            <table style="TEXT-ALIGN: left; WIDTH: 900px" border="0" cellspacing="0" cellpadding="0">
              <tbody>
              <tr>
                <td class="item"><a href="#Top">Home</a></td>
                <td class="item" style="WIDTH: 40px"></td>
                <td class="item"><a href="#Biography">Biography</a></td>
                <td class="item" style="WIDTH: 40px"></td>
                <td class="item"><a href="#Education">Education</a></td>
                <td class="item" style="WIDTH: 40px"></td>
                <td class="item"><a href="#Research">Research</a></td>
                <td class="item" style="WIDTH: 40px"></td>
<!--                <td class="item"><a href="http://www.h265.net/" target="_blank">Blog</a></td>  -->
                <td style="WIDTH: 540px"></td></tr>
             <tr><td style="HEIGHT: 30px;WIDTH: 900px" colspan="12"></td></tr></tbody></table></center>
          </td></tr></tbody></table>
<!--================================End of Header of Windows Body====================================-->

<!--================================Begin of Body of Windows Body====================================-->
            <table id="main" border="0" cellspacing="0" cellpadding="0" width="900">
              <tbody>
              <tr>
                <td style="BACKGROUND-COLOR: #fcfcfc; WIDTH: 100%; OVERFLOW: hidden" valign="top">
                
                  <div id="divContentHome" class="content_div_block">
                  <table class="garde_table_photo" align="center" border="0">
                    <tbody>
                    <tr>
                      <td style="width:412px;height:200px;background-color: #FFFFFF; font-family:garamond; font-size:13px; padding: 10px 20px 10px 20px ; border: 1px solid #D2D2D2;">
                      	<table>
							<tbody><tr>
								<td colspan="2" style="width:165px; height:44px;"><a href="https://sydney.edu.au" target="_blank"><img src="Resources/Icons/usyd-icon.png" height="120px"></a></td>								
<!--								<td colspan="2" style="width:412px; height:44px;"><img src="cu-hk-university.jpg" alt="CUHK" width="308px" height="70px"></td> -->
							</tr>
							<tr>
								<td colspan="2" style="width:412px; height:20px;"></td>
							</tr>
							<tr>
								<td colspan="2" style="width:412px; height:22px;"><b style="font-family:garamond; font-size: 19px;font-weight: bold;">Wanli Ouyang, Ph.D, IEEE Senior Member.</b></td>
							</tr>
							<tr>
								<td colspan="2" style="width:412px; height:22px;"> <b style="font-family:garamond; font-size: 15px;">Senior Lecturer at the University of Sydney</b></td>
							</tr>
							<tr>
								<td colspan="2" style="width:412px; height:22px;"> <b style="font-family:garamond; font-size: 15px;">I'm with <a class="aLink" href="http://mmlab.ie.cuhk.edu.hk/" target="_blank"><i> MMlab </i></a> and <a class="aLink" href="https://sigmalab-usyd.github.io/" target="_blank"><i> SIGMA lab</i></a> </b></td>
							</tr>
						</tbody></table>
						<table cellspacing="0" cellpadding="0" border="0" width="100%">
							<tbody><tr>
								<td bgcolor="#0099FF"><img src="transparent.gif" alt="" width="1" height="1" border="0"></td>
							</tr>
						</tbody></table>
						<table>
							<tbody><tr>
								<td style="width:210px; height:44px; line-height:125%; ">
								<a class="aLink" href="https://sigmalab-usyd.github.io/" target="_blank"> SIGMA lab</a>, <a class="aLink" href="https://sydney.edu.au/engineering/about/school-of-electrical-and-information-engineering.html" target="_blank"> School of Electrical and Information Engineering, </a> <br>
								<a class="aLink" href="https://sydney.edu.au/" target="_blank"> The University of Sydney, </a> <br>
								Sydney, Australia<br>
								</td>
								<td style="width:182px; height:44px; line-height:125%; text-align:left;">
								<br>
								<br>
								<img src="mainpa1.gif" alt="CUHK" width="80px" height="12px">sydney.edu.au<br>
								</td>
							</tr>
						</tbody></table>
<!--						<table>
							<tbody><tr>
								<td colspan="2" style=" line-height:50%; text-align:center;VERTICAL-ALIGN:middle; width:356px; height:10px;">www.interdigital.com</td>
							</tr> 
						</tbody>
						</table>-->
                      </td>
                      <td width="150px"></td>
                      <td style="VERTICAL-ALIGN: middle; width:120px"><img alt="Photo" src="Wanli-New.jpg" width="180px" height="200px"></td>
                      <td width="167px"></td>
                     </tr>
                    </tbody>
                  </table>
				  </div>
                  <div id="divContentBiography" class="content_div_block"><a name="Biography"></a>
                  <h1>Biography</h1>
                  <p class="garde_p">
                  	Wanli Ouyang obtained Ph.D from <a class="aLink" href="http://www.ee.cuhk.edu.hk/" target="_blank">  the Dept. of Electronic Engineering </a>, 
                  	the Chinese University of Hong Kong. 
                  	He is now a Senior Lecturer (equivalent to associate professor in US university systems) at the University of Sydney.
                  	His research interests include deep learning and its application to computer vision and pattern recognition, image and video processing.  <br><br> 

<!-- Dr. Dong received the B.Eng. and M.Eng. degrees, both in Information Engineering from 
                  <a class="aLink" href="http://www.zju.edu.cn/english/" target="_blank">Zhejiang University</a>, Hangzhou, China, 
                  in 2002 and 2005, respectively, and received the Ph.D. degree in Electronic Engineering in 2009, from 
                  <a class="aLink" href="http://www.cuhk.edu.hk/english/" target="_blank">the Chinese University of Hong Kong</a>, 
                  Hong Kong, China, where she worked as a Postdoctoral Fellow in the following year. In 2011,
                  she joined the CTO Office of 
                  <a class="aLink" href="http://www.interdigital.com/" target="_blank">InterDigital Communications</a>, U.S.A.,
                  as Staff Engineer. From 2003 to 2009, she was an active participant in Chinese standardization for 
                  multimedia with successful submissions to 
                  <a class="aLink" href="http://www.avs.org.cn/english/" target="_blank">AVS workgroup</a>. She has been engaged in 
                  HEVC standardization effort since 2011. 
                  Her research interests include high efficiency video coding and real-time video processing.<br><br> -->
				  <a target="_blank" class="aLink" href="./CV_WanliOuyang_CUHK.pdf"><img src="Resources/Icons/pdf-icon.png" width="15px" height="15px" alt="CV PDF" border="0"> Download Wanli Ouyang's Full CV</a>
				  &nbsp;&nbsp;&nbsp;&nbsp;
				  <a target="_blank" class="aLink" href="http://hk.linkedin.com/pub/wanli-ouyang/24/61b/293">
				  <img src="Resources/Icons/linkedin-icon.png" width="15px" height="15px" alt="View Wani Ouyang&#39;s LinkedIn Profile" border="0">View Wanli Ouyang's LinkedIn Profile</a> 
				  &nbsp;&nbsp;&nbsp;&nbsp;
				  <a target="_blank" class="aLink" href="http://scholar.google.com/citations?user=pw_0Z_UAAAAJ&amp hl=en">
				  <img src="Resources/Icons/google-icon.png" width="15px" height="15px" alt="View Wani Ouyang&#39;s Google Scholar Citations" border="0"> View Wanli Ouyang's Google Scholar Citations</a><br><br>
                  <a class="aLink" href="./#Top">Back To Top</a> <br><br> </p>
</div>
                  <h1>Information for potential Postdoctoral Fellow, Master and Ph.D. students and Final Year Program students </h1>                   
                  I moved  <a href="http://sydney.edu.au/engineering/electrical/"> the School of Electrical and Information Engineering, University of Sydney </a> as senior lecturer on 2017. 
                  If you are interested in my research topic and this university, please feel free to contact me <strong> after reading the information available <a href="https://sigmalab-usyd.github.io/recruitment/"> here</a> </strong>.
                  <h1>News </h1>                   
									International Journal of Computer Vision (IJCV) <strong><a href="http://www.ee.oulu.fi/~lili/IJCVSIEVR2018.htm">Special Issue on Efficient Visual Recognition </a></strong>. Due date for submission of full papers: February 15, 2019.
									<br>	<br>
									
                  <h1>Talks </h1>
<a href="./talk/Wanli_AutoML.pdf"> My recent talk on 'From Manual Design to Automatic Deep Learning'</a>
<br> <br>
<a href="./talk/Tutorial_2019_China_PRCV_out.pdf"> My recent tutorial on 'Deep learning in object detection' at PRCV 2019 </a>
<br> <br>
<a href="./talk/Talk2019_China_Jan_4_out.pdf">  My recent talk on ‘Structured deep learning for visual localization and recognition’  </a>
<br> <br>

<a href="./talk/ACCV18_3D_scene_understanding.pdf">  My talk ‘Modeling deep structures for 3D scene understanding’ at ACCV 2018 workshop </a>
									<br>	<br>

<a href="./talk/ACCV18_High_Performance.pdf">  My talk ‘Modeling deep structures for using high performance images’ at ACCV 2018 workshop </a>
<br> <br>




<!----																	<a href="./projects/GBD/index.html">Our team rank as #1 for object detection with provided data and external data and #1 for video object detection/tracking in the ImageNet Large Scale Visual Recognition Challenge 2016. Project page with source code </a> <br /> -->

                  <h1>Good resources on Paper Writing </h1>         
                  <a href="http://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&mid=2649439633&idx=1&sn=f9a6b894e4266a6e5ec4b6ec673255a2&chksm=82c0d415b5b75d03faa511eb691630d2e5d3ed2fbe3598629ab20a037b8d95bfa5c795ad1c66&mpshare=1&scene=1&srcid=1205JJGMMw3BmvYdPXJBrNyq##"> How to do good research on computer vision (Chinese) </a> <br />                            
                  <a href="http://ec.europa.eu/eurostat/documents/64157/4374310/33-UNECE-making-data-meaningful-Part2-EN.pdf/d5b954e2-b110-469b-a2b5-78aa7c12ab62"> Making Data meaningful </a> <br />
                  <a href="https://www.dropbox.com/s/wgrdpmxcmb4nhl0/How%20to%20Get%20Your%20CVPR%20Paper%20Rejected.pptx?dl=0"> Slides on "How to get your paper rejected." By Prof. Ming-Hsuan Yang from UC Merced </a> <br />
                  <a href="http://blog.csdn.net/daiyuchao/article/details/6419543"> Chinese blog on how to publish a top journal </a> <br />

                  <h1>Good advices for Research Students</h1>         
                  <a href="https://mp.weixin.qq.com/s?__biz=MzI0NTY5ODMzMQ==&mid=2247485969&idx=1&sn=0766ff7f65828486725c722c88101a07&chksm=e94bd065de3c59735e2e3876c74e646d2c87e6acdf17157cddcc7fca02afe6261fcbf88b75db&mpshare=1&scene=1&srcid=0207ALoWRslZQnzDDYaKeUNw#rd"> 研究生导师：这种学生，才是我眼中的科研好苗子！(Advice in Chinese)</a> <br />


<!--                   <a href="./projects/ImageNet/index.html">Our team rank as #1 for video object detection and #2 for still image object detection in the ImageNet Large Scale Visual Recognition Challenge 2015. Project page</a> <br />
                  <a href="./projects/ImageNet/index.html">Our team rank as #2 in the ImageNet Large Scale Visual Recognition Challenge 2014. Project page</a> <br /> -->


<!--========================  Recommendation on Papers  ==========================--> 
<div id="divContentResearch" class="content_div_block"><a name="Research"></a>
                  <h1>Chef's Recommendation on Papers </h1>

                  <em> Our recent survey on object detection: </em>   <br>
                  
                  Dongzhan Zhou, Xinchi Zhou, Wenwei Zhang, Chen Change Loy, Shuai Yi, Xuesen Zhang, <strong>Wanli Ouyang</strong>, “EcoNAS: Finding Proxies for Economical Neural Architecture Search”, Proc. <em>CVPR</em>, 2020.
                        <br>  <br>


									Liu, Li, <strong>Wanli Ouyang</strong>, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, and Matti Pietikäinen, "Deep learning for generic object detection: A survey,"  <em>IJCV, accepted</em>, 2019.
												[<a class="aLink" href="https://arxiv.org/pdf/1809.02165" target="_blank">Full Text</a>]
                        <br>  <br>

								
									<em> A new back-bone deep model design (performs better than ResNet and DenseNet): </em>   <br>
									Shuyang Sun, Jiangmiao Pang, Jianping Shi, Shuai Yi, <strong>Wanli Ouyang</strong>, "FishNet: A Versatile Backbone for Image, Region, and Pixel Level Prediction,"  <em>NuerIPS. (Previously called NIPS)</em>, 2018.
												[<a class="aLink" href="http://papers.nips.cc/paper/7356-fishnet-a-versatile-backbone-for-image-region-and-pixel-level-prediction.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" href="https://github.com/kevin-ssy/FishNet" target="_blank"> Source code </a>]
                        <br>  <br>

									<em> The first end-to-end deep video compression model: </em> <br>
									Guo Lu, <strong>Wanli Ouyang</strong>, Dong Xu, Xiaoyun Zhang, Chunlei Cai, Zhiyong Gao, "DVC: An End-to-end Deep Video Compression Framework," In Proc. CVPR 2019. 												[<a class="aLink" href="https://arxiv.org/pdf/1812.00101" target="_blank">Full Text</a>]  [<a class="aLink" href="https://github.com/GuoLusjtu/DVC" target="_blank">Source code</a>]
                        <br>  <br>

									<em> Details on our wining entry in ImageNet 2016 challenge on object detection: </em>   <br>
                      	Xingyu Zeng (equal contribution), <strong>Wanli Ouyang</strong> (equal contribution), Junjie Yan, Hongsheng Li, Tong Xiao, Kun Wang, Yu Liu, Yucong Zhou, Bin
Yang, Zhe Wang, Hui Zhou, Xiaogang Wang,
                      "Crafting GBD-Net for Object Detection," 
                      <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, accepted, 2017.
												[<a class="aLink" href="./Papers/Zeng2017_GBD_PAMI.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" href="./projects/GBD/index.html" target="_blank">Project page & code </a>]												
												[<a class="aLink" href="https://github.com/craftGBD/craftGBD" target="_blank"> Source code </a>]
                        <br>  <br>


<em> The first work modeling deformation in deep CNN, used for pedestrian detection: </em>   <br>
                      	<strong>Wanli Ouyang</strong>, Hui Zhou, Hongsheng Li, Quanquan Li, Junjie Yan, Xiaogang Wang,
                      "Jointly learning deep features, deformable parts, occlusion and classification for pedestrian detection," 
                      <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, 40(8):1874-1887, 2018.
												[<a class="aLink" href="./Papers/Ouyang2017JoingCNNPed.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" href="https://github.com/xiaohuige1/udn_extend" target="_blank">Source code</a>]                        <br>  <br>

<em> Extend our work on modeling deformation for generic object detection. This new deformation handling layer can be placed anywhere. </em>   <br>
									<strong>Wanli Ouyang</strong>, Xingyu Zeng,  Xiaogang Wang, et al,
                      "DeepID-Net: Object Detection with Deformable Part Based Convolutional Neural Networks," 
                      <em>IEEE Trans. Pattern Anal. Mach. Intell. (PAMI)</em>, accepted, 2016.
												[<a class="aLink" href="./Papers/DeepID-Net.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Project" href="./projects/ImageNet/index.html" target="_blank">Project</a>]																								<br>  <br>
                          
												
									<em> The first cascade network for generic object detection. </em>   <br>
                      	<strong>Wanli Ouyang</strong>, Kun Wang, Xin Zhu, Xiaogang Wang. "Chained Cascade Network
for Object Detection", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Ouyang_Chained_Cascade_Network_ICCV_2017_paper.pdf" target="_blank">Full Text</a>]  
[<a class="aLink" title="Download source code" href="https://github.com/wk910930/ccnn" target="_blank">Source code</a>]  	
                        <br>  
												<br>
												
<em> A simple and effective multi-scale feature operation. Showing and solving the initialization problem in existing multi-branch networks, e.g. Inception V2-V5, Hourglass, ResNxt, etc. </em>   <br>

												Wei Yang, Shuang Li, <strong>Wanli Ouyang</strong>, Hongsheng Li, XiaogangWang. "Learning Feature Pyramids for Human Pose Estimation", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Yang_Learning_Feature_Pyramids_ICCV_2017_paper.pdf" target="_blank">Full Text</a>] [<a class="aLink" title="Code on Github" href="https://github.com/bearpaw/PyraNet" target="_blank">Source code</a>]
                        <br>  <br>



									<em> The first work on structured feature learning. </em>   <br>
                      	X. Chu,  <strong>Wanli Ouyang</strong> , H. Li, and X. Wang. 
                      	"Structured feature learning for pose estimation",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="http://arxiv.org/pdf/1603.09065.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Project" href="http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html" target="_blank">Project and dataset </a>]                          
                        [<a class="aLink" title="Project" href="https://www.youtube.com/watch?v=SMFt6TJ-ntA" target="_blank">Spotlight talk</a>]                          
                        [<a class="aLink" title="Code" href="https://github.com/chuxiaoselena/StructuredFeature" target="_blank">Source code </a>]                          
                        [<a class="aLink" title="Supplementary" href="http://www.ee.cuhk.edu.hk/~xgwang/StructureFeature/supp.pdf" target="_blank">Supplementary </a>]                          
                          <br>
                        <br>

									<em> The first Fully Convolutional Network for visual tracking. </em> <br>
                      	Lijun Wang,  <strong>Wanli Ouyang</strong>, Xiaogang Wang, and Huchuan Lu,
                      	"Visual Tracking with Fully Convolutional Networks",  In <em>Proc. ICCV </em> 2015. 
                        [<a class="aLink" title="Download Full Text" href="Papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf" target="_blank">Full Text</a>]  
                      [<a class="aLink" title="Project" href="http://scott89.github.io/FCNT/" target="_blank">Project and source code </a>]                

                  
                  
                  
                  
                  
                  
                  
<!--========================Journal Papers ========================-->                  
                  
                  <h1>Journal Papers</h1>

                  
                  
                  <table border="0" cellspacing="0" cellpadding="5" width="900">
                    <tbody id="journal_list">

                      <tr class="pub_tr_1">  
                      <td width="20%" align="left" colspan="2" style="HEIGHT:10px"></td></tr>
                      <tr class="pub_tr_1">  
                      <td width="20%" align="left" colspan="2"><a class="aLink" href="#Top">Back To Top</a></td></tr>
                    
                    </tbody>
                  </table>

                    
                      	
<!--========================Conference Papers ========================-->                      	
                  <h1>Conference Papers</h1>
                  <table border="0" cellspacing="0" cellpadding="5" width="900">
                    <tbody id="conference_list">
                

                        


												
                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"> <img alt="OHT_Complexity" border="0" src="./imgs/Encapsule.jpg" width="304px" height="100" ><img alt="OHT_Complexity" border="0" src="./imgs/FactorizableNet.jpg" width="304px" height="200" >
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">												
Hongyang Li, Bo Dai, <strong>Wanli Ouyang</strong>, Xiaoyang Guo, Xiaogang Wang. "Neural
Network Encapsulation ", <em>Proc. ECCV</em>, 2018.[<a class="aLink" title="Download Code" href=" https://github.com/hli2020/nn_capsulation" target="_blank">Code link</a>] [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Hongyang_Li_Neural_Network_Encapsulation_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>		
												<br>
Yi Wei, Xinyu Pan, Hongwei Qin, Junjie Yan, <strong>Wanli Ouyang</strong>, "Quantization
Mimic: Towards Very Tiny CNN for Object Detection". <em>Proc. ECCV</em>, 2018. [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yi_Wei_Quantization_Mimic_Towards_ECCV_2018_paper.pdf" target="_blank">Full Text</a>] 
                        <br>
											  <br>
Yikang Li, <strong>Wanli Ouyang</strong>, Bolei Zhou, Yanwen Cui, Jianping Shi, Chao Zhang, Xiaogang Wang. "Factorizable Net: An Efficient Subgraph-based Framework for
Scene Graph Generation" <em>Proc. ECCV</em>, 2018. [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yikang_LI_Factorizable_Net_An_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
[<a class="aLink" title="Download Code" href="https://github.com/yikang-li/FactorizableNet" target="_blank">Source code</a>]
                        <br>																				
                        <br>
Guo Lu, <strong>Wanli Ouyang</strong>, Dong Xu, Xiaoyun Zhang, Zhiyong Gao, Ming-Ting Sun, "Deep Kalman Filtering Network for Video Compression Artifact Reduction". <em>Proc. ECCV</em>, 2018.  [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Guo_Lu_Deep_Kalman_Filtering_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
											  <br>
Dongang Wang, <strong>Wanli Ouyang</strong>, Wen Li, Dong Xu, "Dividing and Aggregating
Network for Multi-view Action Recognition", <em>Proc. ECCV</em>, 2018.  [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Dongang_Wang_Dividing_and_Aggregating_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
											  <br>
Di Chen, Shanshan Zhang, <strong>Wanli Ouyang</strong>, Jian Yang, Ying Tai, "Person Search
via A Mask-guided Two-stream CNN Model". <em>Proc. ECCV</em>, 2018.  [<a class="aLink" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Di_Chen_Person_Search_via_ECCV_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
																		
								      </td>
									</tr>       
									
											
                  <tr class="pub_tr_2">
                     <td width="20px" class="pub_td_number"> </td>
                   <td width="304px" style="vertical-align: middle"> <img alt="OHT_Complexity" border="0" src="./imgs/OFF.jpg" width="304px" height="200" ></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">  
											
                      	Xuanyi Dong, Yan Yan, <strong>Wanli Ouyang </strong>, Yi Yang. "Style Aggregated Network for Facial Landmark Detection", <em>Proc. CVPR</em>, 2018.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Dong_Style_Aggregated_Network_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Yikang Li, Nan Duan, Bolei Zhou, Xiao Chu, <strong>Wanli Ouyang</strong>, Xiaogang Wang. "Visual Question Generation as Dual Task of Visual Question Answering", <em>Proc. CVPR</em>, 2018 (spotlight).
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Visual_Question_Generation_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" title="Download Code" href="https://github.com/yikang-li/iQAN" target="_blank">Source code</a>]
                        <br>
                        <br>
                      	Jing Xu, Rui Zhao, Feng Zhu, Huaming Wang, <strong>Wanli Ouyang</strong>. "Attention-aware Compositional Network for Person Re-Identification", <em>Proc. CVPR</em>, 2018. [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Attention-Aware_Compositional_Network_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Yu Wu, Yutian Lin, Xuanyi Dong, Yan Yan, <strong>Wanli Ouyang</strong>, Yi Yang. "Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning", <em>Proc. CVPR</em>, 2018.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Exploit_the_Unknown_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Wei Yang, <strong>Wanli Ouyang</strong>, Xiaolong Wang, Xiaogang Wang. "3D Human Pose Estimation in the Wild by Adversarial Learning", <em>Proc. CVPR</em>, 2018.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_3D_Human_Pose_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Watch Video on Youtube" href="https://youtu.be/LAxVl4zQT-A" target="_blank">Video</a>]
												<br>
                        <br>
                      	Weichen Zhang, <strong>Wanli Ouyang</strong>, Dong Xu, Wen Li. "Collaborative and Adversarial Network for Unsupervised domain adaptation", <em>Proc. CVPR</em>, 2018. (Spotlight) [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Collaborative_and_Adversarial_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Shuyang Sun, Zhanghui Kuang, Lu Sheng, <strong>Wanli Ouyang</strong>, Wei Zhang. "Optical Flow Guided Feature: A Motion Representation for Video Action Recognition", <em>Proc. CVPR</em>, 2018.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Sun_Optical_Flow_Guided_CVPR_2018_paper.pdf" target="_blank">Full Text</a>]												[<a class="aLink" title="Download Source code" href="https://github.com/kevin-ssy/Optical-Flow-Guided-Feature" target="_blank">Source code</a>]                         
												<br>
                        <br>
                      	Dan Xu, <strong>Wanli Ouyang</strong>, Xiaogang Wang, Nicu Sebe. "PAD-Net: Multi-Tasks Guided Prediciton-and-Distillation Network for Simultaneous Depth Estimation and Scene Parsing", <em>Proc. CVPR</em>, 2018.
												[<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.pdf" target="_blank">Full Text</a>] 
                        <br>
                        <br>
                      	Chunfeng Song, Yan Huang, Liang Wang, <strong>Wanli Ouyang</strong>. "Mask-guided Contrastive Attention Model for Person Re-Identification ", <em>Proc. CVPR</em>, 2018. 
												[<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Song_Mask-Guided_Contrastive_Attention_CVPR_2018_paper.pdf" target="_blank">Full Text</a>] 
[<a class="aLink" title="Download Code" href="https://github.com/developfeng/MGCAM" target="_blank">Source Code</a>]
                        <br>
                        <br>
                      	Lingbo Liu, HongjunWang, Guanbin Li, <strong>Wanli Ouyang</strong>, Liang Lin, "Crowd Counting using Deep Recurrent Spatial-Aware Network", <em>Proc. IJCAI</em>, 2018. [<a class="aLink" title="Download Full Text" href="https://www.ijcai.org/proceedings/2018/0118.pdf" target="_blank">Full Text</a>] 
								    </td>       
                 </tr>       



                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px"> <img alt="OHT_Complexity" border="0" src="./images/ChainCNN.JPG" width="304px" height="240">
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	<strong>Wanli Ouyang</strong>, Kun Wang, Xin Zhu, Xiaogang Wang. "Chained Cascade Network
for Object Detection", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Ouyang_Chained_Cascade_Network_ICCV_2017_paper.pdf" target="_blank">Full Text</a>] [<a class="aLink" title="Download source code" href="https://github.com/wk910930/ccnn" target="_blank">Source code</a>]  	
                        <br>
                        <br>
                      	Wei Yang, Shuang Li, <strong>Wanli Ouyang</strong>, Hongsheng Li, XiaogangWang. "Learning Feature Pyramids for Human Pose Estimation", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Yang_Learning_Feature_Pyramids_ICCV_2017_paper.pdf" target="_blank">Full Text</a>] [<a class="aLink" title="Code on Github" href="https://github.com/bearpaw/PyraNet" target="_blank">Code</a>]
                        <br>
                        <br>
                      	Yikang Li, <strong>Wanli Ouyang</strong>, Bolei Zhou, Kun Wang, Xiaogang Wang. "Scene
Graph Generation from Objects, Phrases and Region Captions", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Scene_Graph_Generation_ICCV_2017_paper.pdf" target="_blank">Full Text</a>]
												[<a class="aLink" title="Download Code" href="https://github.com/yikang-li/MSDN" target="_blank">Source code</a>]												
												<br>
                        <br>
                      	Qi Chu, <strong>Wanli Ouyang</strong>, Hongsheng Li, Xiaogang Wang, Bin Liu, Nenghai
Yu. "Online Multi-Object Tracking Using CNN-based Single Object Tracker with
Spatial-Temporal Attention Mechanism", <em>Proc. ICCV</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Chu_Online_Multi-Object_Tracking_ICCV_2017_paper.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Dan Xu, <strong>Wanli Ouyang</strong>, Xavier Alameda-Pineda, Elisa Ricci, Xiaogang Wang,
Nicu Sebe. "Learning Deep Structured Multi-Scale Features using Attention-Gated
CRFs for Contour Prediction", <em>Proc. NIPS</em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="http://papers.nips.cc/paper/6985-learning-deep-structured-multi-scale-features-using-attention-gated-crfs-for-contour-prediction.pdf" target="_blank">Full Text</a>]
                       
                 </tr>       




                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                   <td width="304px"> <img alt="OHT_Complexity" border="0" src="./images/vip-cnn.jpg" width="304px" height="350">
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	Kai Kang, Hongsheng Li, <strong> W. Ouyang </strong>, Junjie  Yan, Xihui  Liu, Tong  Xiao, Xiaogang  Wang. ”Object Detection in Vidoes with Tubelet Proposal Networks”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/abs/1702.06355" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Feng  Zhu, Hongsheng Li, <strong> W. Ouyang </strong>, Nenghai  Yu, Xiaogang  Wang. ”Learning Spatial Regularization with Image-level Supervisions for Multi-label Image Classification”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/pdf/1702.05891" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Yu Liu, Junjie  Yan, <strong> W. Ouyang </strong>. ”Quality Aware Network for Set to Set Recognition”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/pdf/1704.03373" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Yikang  LI , <strong> W. Ouyang </strong>, Xiaogang  Wang. ”ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/pdf/1702.07191" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Xiao  Chu, Wei  Yang, <strong> W. Ouyang </strong>, Xiaogang  Wang, Alan  Yuille. ”Multi-Context Attention for Human Pose Estimation”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/pdf/1702.07432" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Download Source code" href="https://github.com/bearpaw/pose-attention" target="_blank">Code</a>]                        
                        
                        <br>
                        <br>
                      	Dan  Xu, Elisa  Ricci, <strong> W. Ouyang </strong>, Xiaogang  Wang, Nicu Sebe. Multi-Scale Continuous CRFs as Sequential Deep Networks for Monocular Depth Estimation”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/abs/1704.02157" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Download Source code" href="https://github.com/danxuhk/ContinuousCRF-CNN" target="_blank">Code</a>]                        
                        [<a class="aLink" title="Presentation" href="https://youtu.be/4mdqh6YGhgE" target="_blank">Presentation</a>]                              <br>
                        <br>
                      	Dan  Xu,  <strong> W. Ouyang </strong>,  Elisa  Ricci, Xiaogang  Wang, Nicu Sebe. Learning Cross-Modal Deep Representations for Robust Pedestrian Detection”,<em> Proc. CVPR </em>, 2017.
                        [<a class="aLink" title="Download Full Text" href="https://arxiv.org/abs/1704.02431" target="_blank">Full Text</a>]

                 <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="./images/CRF_CNN.jpg" width="304px" height="65"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	X. Chu, <strong> W. Ouyang </strong>, H. Li, X. Wang. ”CRF-CNN: Modeling Structured Information in Human Pose Estimation”,<em> Advances In Neural Information Processing Systems (NIPS)</em>, 2016.
                        [<a class="aLink" title="Download Full Text" href="./Papers/CRF-CNN_NIPS16" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Download Demo Results" href="http://www.ee.cuhk.edu.hk/~xchu/files/nips_2016_supp.pdf" target="_blank">Demo Results</a>]
                      </td>
                 </tr>       


                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="./projects/GBD/images/motivation.jpg" width="304px" height="200"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	Xingyu Zeng, <strong>Wanli Ouyang</strong>, Bin Yang, Junjie Yan, Xiaogang
                      	"Gated Bidirectional CNN for Object Detection",  In <em>Proc. ECCV </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/GBD.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Z. Wang, H. Li, <strong>W. Ouyang </strong>, X. Wang Wanli
                      	"Learnable Histogram: Statistical Context Features for Deep Neural Networks",  In <em>Proc. ECCV </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/HistDNN.pdf" target="_blank">Full Text</a>]
                        
                    </td>
                 </tr>       
                        
                      	
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/ImageNetFactors.jpg" width="304px" height="200"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	<strong>Wanli Ouyang</strong>, X. Wang, C. Zhang, and X. Yang.
                      	"Factors in finetuning deep model for object detection with long-tail distribution",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/OuyangFactors_CVPR16.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Wei Yang, <strong>Wanli Ouyang</strong>, Hongsheng Li and Xiaogang Wang
                      	"End-to-End Learning of Deformable Mixture of Parts and Deep Convolutional Neural Networks for Human Pose Estimation",  In <em>Proc. CVPR </em> 2016 (Oral). 
                        [<a class="aLink" title=" Download Full Text" href="http://www.ee.cuhk.edu.hk/~xgwang/papers/yangOLWcvpr16.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title=" Project" href="http://www.ee.cuhk.edu.hk/~wyang/Deep-Deformable-Mixture-of-Parts-for-Human-Pose-Estimation/" target="_blank">Project</a>]
												[<a class="aLink" title="Download Source Code" href="https://github.com/bearpaw/eval_pose" target="_blank">Source Code</a>]
												
												
                        <br>
                        <br>
                      	Lijun Wang, <strong>Wanli Ouyang</strong>, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu.
                      	"STCT: Sequentially Training Convolutional Networks for Visual Tracking",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/WangLJ_CVPR16.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	K. Kang, <strong>Wanli Ouyang</strong>, H. Li, and X. Wang.
                      	"Object detection from video tubelets with convolutional neural networks",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./Papers/KangVideoDet_CVPR16.pdf" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	X. Chu,  <strong>Wanli Ouyang</strong> , H. Li, and X. Wang. 
                      	"Structured feature learning for pose estimation",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="http://arxiv.org/pdf/1603.09065.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Project" href="http://www.ee.cuhk.edu.hk/~xgwang/projectpage_structured_feature_pose.html" target="_blank">Project and dataset </a>]                          
                        [<a class="aLink" title="Project" href="https://www.youtube.com/watch?v=SMFt6TJ-ntA" target="_blank">Spotlight talk</a>]                          
                        [<a class="aLink" title="Code" href="https://github.com/chuxiaoselena/StructuredFeature" target="_blank">Source code </a>]                          
                        [<a class="aLink" title="Supplementary" href="http://www.ee.cuhk.edu.hk/~xgwang/StructureFeature/supp.pdf" target="_blank">Supplementary </a>]                          
                          <br>
                        <br>
                      	Tong Xiao, Hongsheng Li, <strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Learning Deep Feature Representations with Domain Guided Dropout for Person Re-identification",  In <em>Proc. CVPR </em> 2016. 
                        [<a class="aLink" title="Full Text on Arxiv" href="http://arxiv.org/abs/1604.07528" target="_blank">Full Text</a>]
                        <br>
                        <br>
                      	Hongyang Li, <strong>Wanli Ouyang</strong>, Xiaogang Wang
                      	"Multiple Bias on Non-linearity Activation in Deep Neural Networks",  In <em>Proc. ICML </em> 2016. 
                        [<a class="aLink" title="Download Full Text" href="./MBA_icml16.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Slides" href="http://www.ee.cuhk.edu.hk/~yangli/icml16_bias.pdf" target="_blank">Slides </a>]                          
                        [<a class="aLink" title="Code" href="https://github.com/hli2020/caffe/tree/bias" target="_blank">Code on Github </a>]                          
                      	
                    </td>
                 </tr>       



                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="projects/ImageNetAttribute/dataset.png" width="304px" height="120"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	<strong>Wanli Ouyang</strong>, Hongyang Li, Xingyu Zeng, and Xiaogang Wang,
                      	"Learning Deep Representation with Large-scale Attributes",  In <em>Proc. ICCV </em> 2015. 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_ICCV&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_ICCV&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="./Papers/ImageNetAttributes_ICCV15.pdf" target="_blank">Full Text</a>]  
                        [<a class="aLink" title="Project" href="./projects/ImageNetAttribute/iccv15.html" target="_blank">Project and dataset </a>]                          
                        <br>
                        
                        
                        </td></tr>                        
               
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/Immediacy.PNG" width="304px" height="150"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	Xiao Chu, <strong>Wanli Ouyang</strong>, Wei Yang, and Xiaogang Wang,
                      	"Multi-task Recurrent Neural Network for Immediacy Prediction",  In <em>Proc. ICCV </em> 2015.<strong> (Oral) </strong>
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_ICCVXchu&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_ICCVXchu&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="./Papers/Chu_Multi-Task_Recurrent_Neural_ICCV_2015_paper.pdf" target="_blank">Full Text</a>]  
                        [<a class="aLink" title="Project" href="http://www.ee.cuhk.edu.hk/~xgwang/projectpage_immediacy.html" target="_blank">Project and dataset </a>]                          
                        [<a class="aLink" title="Oral" href="http://videolectures.net/iccv2015_chu_neural_network/" target="_blank">Oral presentation on videolectures</a>]                          
                        [<a class="aLink" title="Poster" href="http://www.ee.cuhk.edu.hk/~xchu/files/iccv_2015_poster.pdf" target="_blank">Poster</a>]                          
                        <br>
                        
                        
</td></tr>                        
             

                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/Tracking_ICCV15.png" width="304px" height="150"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <br>
                      	Lijun Wang,  <strong>Wanli Ouyang</strong>, Xiaogang Wang, and Huchuan Lu,
                      	"Visual Tracking with Fully Convolutional Networks",  In <em>Proc. ICCV </em> 2015. 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_ICCVWang&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_ICCVWang&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="Papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf" target="_blank">Full Text</a>]  
                      [<a class="aLink" title="Project" href="http://scott89.github.io/FCNT/" target="_blank">Project and source code </a>]                
                        <br>
                        
                        
</td></tr>                        

                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/overview_DeepID.png" width="304px" height="120"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> <strong>Details that show how our team achieve #2 in the ImageNet Large Scale Visual Recognition Challenge 2014: </strong> <br>
                      	<strong>Wanli Ouyang</strong>, Xiaogang Wang, Xingyu Zeng, Shi Qiu, Ping Luo, Yonglong Tian, Hongsheng Li, Shuo Yang, Zhe Wang, Chen-Change Loy and Xiaoou Tang,
                      	"DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection",  In <em>Proc. CVPR </em> 2015. 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_CVPR1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_CVPR1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="./Papers/DeepIDNet_CVPR15.pdf" target="_blank">Full Text</a>]  
                        [<a class="aLink" title="Project" href="./projects/ImageNet/index.html" target="_blank">Project</a>]                          
                        <br>
                        
                        
                        </td></tr>                        
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/ZhaoCVPR15.JPG" width="304px" height="120"></td> 
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">  <br>
                      	Rui Zhao, <strong>Wanli Ouyang</strong>,  Hongsheng Li, and Xiaogang Wang,
                      	"Saliency Detection by Multi-context Deep Learning",  In <em>Proc. CVPR </em> 2015. 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2015_CVPR2&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2015_CVPR2&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~rzhao/project/deepsal_cvpr15/zhaoOLWcvpr15.pdf" target="_blank">Full Text</a>]  
                        [<a class="aLink" title="Code" href="https://github.com/Robert0812/deepsaldet" target="_blank">Code</a>]                          
                        [<a class="aLink" title="Supplementary Material" href="http://www.ee.cuhk.edu.hk/~rzhao/project/deepsal_cvpr15/zhaoOLWcvpr15.html" target="_blank">Supplementary Material</a>]                          
                        <br>
                                                
                         
                        </td></tr>                        
                        
                                               
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <!--<img alt="OHT_Complexity" border="0" src="imgs/ZengECCV14.jpg" width="304px" height="256px">--></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">Xinyu Zeng, <strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Deep Learning of Scene-Specific Classifier for Pedestrian Detection", In <em>Proc. ECCV </em> 2014.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="http://link.springer.com/chapter/10.1007/978-3-319-10578-9_31" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                                            	
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/PoseDBN.PNG" width="304px" height="256px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Xiao Chu, Xiaogang Wang, 
                      	"Multi-source Deep Learning for Human Pose Estimation", In <em>Proc. IEEE CVPR </em> 2014.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~xgwang/papers/ouyangCWcvpr14.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/ZhaoCVPR14.JPG" width="304px" height="180px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> Rui Zhao,  <strong>Wanli Ouyang</strong>, and Xiaogang Wang, 
                      	"Learning Mid-level Filters for Person Re-Identfiation", In <em>Proc. IEEE CVPR </em> 2014.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2014_CVPR2&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2014_CVPR2&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project page" href="http://www.ee.cuhk.edu.hk/~rzhao/project/midfilter_cvpr14/zhaoOWcvpr14.html" target="_blank">Project</a>]  
                        [<a class="aLink" title="Download Code" href="https://github.com/Robert0812/midfilter_reid" target="_blank">Code</a>]  
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~rzhao/project/midfilter_cvpr14/zhaoOWcvpr14.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>

                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="imgs/jointdeep.PNG" width="304px" height="256px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Joint Deep Learning for Pedestrian Detection ", In <em>Proc. IEEE ICCV </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="./projects/ouyangWiccv13Joint/index.html" target="_blank">Project & Source code</a>]  
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~xgwang/papers/ouyangWiccv13.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <!--<img alt="OHT_Complexity" border="0" src="imgs/cascade.PNG" width="304px" height="256px">--></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> Xingyu Zeng, <strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Multi-Stage Contextual Deep Learning for Pedestrian Detection ", In <em>Proc. IEEE ICCV </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV2&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV2&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="" target="_blank">Project </a>]  
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~xgwang/papers/zengOWiccv13.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <!--<img alt="OHT_Complexity" border="0" src="imgs/pedestrian_salience2.PNG" width="304px" height="256px">--></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> Rui Zhao, <strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Person Re-identification by Salience Matching ", In <em>Proc. IEEE ICCV </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_ICCV3&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_ICCV3&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="" target="_blank">Project</a>]  
                        [<a class="aLink" title="Download Full Text" href="http://www.ee.cuhk.edu.hk/~rzhao/papers/zhaoOWiccv13.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                                                
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="two_pedestrian.PNG" width="304px" height="156px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Xiaogang Wang, 
                      	"Single-Pedestrian Detection aided by Multi-pedestrian Detection ", In <em>Proc. IEEE CVPR </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_CVPR1&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_CVPR1&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="./projects/ouyangWcvpr13MultiPed/index.html" target="_blank">Project & Source code</a>]  
                        [<a class="aLink" title="Download Full Text" href="./Papers/Ouyang2013MultiPed.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="mutual_visibility.PNG" width="304px" height="206px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Xingyu Zeng and Xiaogang Wang, 
                      	"Modeling Mutual Visibility Relationship in Pedestrian Detection ", In <em>Proc. IEEE CVPR </em> 2013.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2013_CVPR2&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2013_CVPR2&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="./projects/ouyangZWcvpr13MutVisibility/index.html" target="_blank">Project</a>]  
                        [<a class="aLink" title="Download Full Text" href="./Papers/Ouyang2013MutualDBN.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>

                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="pedestrian_salience.PNG" width="304px" height="256px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"> Rui Zhao <strong>Wanli Ouyang</strong>, and Xiaogang Wang, 
                      	"Unsupervised Salience Learning for Person Re-identification ", In <em>Proc. IEEE CVPR </em> 2013.
                        [<a class="aLink" title="Project webpage" href="http://mmlab.ie.cuhk.edu.hk/projects/project_salience_reid/index.html" target="_blank">Project & source code</a>]  
                        [<a class="aLink" title="Download Full Text" href="./Papers/ZhaoCVPR2013Salience.pdf" target="_blank">PDF</a>]  
                        </code></div>
                        </td></tr>
                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <!--<img border="0" alt="HumanDBNDetRes" src="HumanDBNDetRes.jpg" width="304px" height="200px">--> </td>
                      <td class="pub_td_text"  width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong> and Xiaogang Wang, 
                      	"A Discriminative Deep Model for Pedestrian Detection with Occlusion Handling," 
                      	In <em>Proc. IEEE CVPR </em> 2012.                      	
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2012_CVPR&#39;)">Abstract</a>]
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2012_CVPR&#39;)">BibTeX</a>]
                        [<a class="aLink" title="Project webpage" href="./projects/ouyangWcvpr12Occ/index.html" target="_blank">Project</a>]  
			[<a class="aLink" href="./Papers/CDBN-Ped12.pdf" target="_blank">  Full Text</a>]
			[<a class="aLink" href="http://www.ee.cuhk.edu.hk/~xgwang/CUHK_pedestrian.html" target="_blank">CUHK Occlusion Dataset</a>]
<!--                          [<a class="aLink" title="Download Poster" href="./2009_icip_poster.pdf" target="_blank">Poster</a>]
                        [<a class="aLink" title="Download Full Text" href="./2009_icip.pdf" target="_blank">Full Text</a>]
                        [<a class="aLink" title="Download Errata" href="./2009_icip_errata.pdf" target="_blank">Errata</a>]     
-->                        <br>
                        
                        
                        </td></tr>
                                                                        
                    <tr class="pub_tr_2">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img alt="OHT_Complexity" border="0" src="mainpa9.gif" width="304px" height="206px"></td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle"><strong>Wanli Ouyang</strong>, Renqi Zhang and Wai-Kuen Cham, 
                      	"Fast pattern matching using orthogonal Haar transform ", In <em>Proc. IEEE CVPR </em> 2010.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2011_iscas&#39;)">Abstract</a>] 
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2011_iscas&#39;)">BibTeX</a>]
			[<a class="aLink" href="./OHT.htm" target="_blank">Project & source code</a>]
                        [<a class="aLink" title="Download Slides" href="./PPT/OHT1.ppt" target="_blank">Slides</a>]
                        [<a class="aLink" title="Download Full Text" href="./Papers/Manu_OHT.pdf" target="_blank">Full Text</a>]  
                        <br>
                        
                        
                        </td></tr>
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img border="0" alt="Img_coded" src="mainpa12.jpg" width="147px" height="161px"><img border="0"  alt="Img_filtered" src="mainpa13.jpg" width="147px" height="161px"> </td>
                      <td class="pub_td_text" width="500px" style="vertical-align: middle">Renqi Zhang, <strong>Wanli Ouyang</strong> and Wai-Kuen Cham, 
                      	"Image Deblocking using Dual Adaptive FIR Wiener Filter in the DCT Transform Domain," 
                      	<em>In Proc. IEEE Int. Conf. Acoustics, Speech, and Signal Processing</em>, ICASSP 2009, 
                      	Taiwan, April 19-24, 2009, pp.1181-1184.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2009_icip&#39;)">Abstract</a>]
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2009_icip&#39;)">BibTeX</a>]
<!--                        [<a class="aLink" title="Download Errata" href="./2009_icip_errata.pdf" target="_blank">Errata</a>]     
-->                        <br>
                        
                        
                        </td></tr>
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
                      <td width="304px"> <img border="0" alt="Img_ori" src="mainpa14.jpg" width="100px" height="101px"><img border="0"  alt="Img_canny" src="mainpa15.gif" width="100px" height="101px"> <img border="0"  alt="Img_our3DEdge" src="mainpa16.gif" width="100px" height="101px">  </td>
                      <td class="pub_td_text">Renqi Zhang, <strong>Wanli Ouyang</strong> and Wai-Kuen Cham, 
                      	"Image Multi-scale Edge Detection using 3-D Hidden Markov Model based on the Non-decimated Wavelet," 
                      	In <em> Proc. 2009 IEEE International Conference on Image Processing</em> (ICIP), 
                      	Cairo, Egypt, November 7-10, 2009, pp.2173-2176.
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide Abstract" onclick="JavaScript:menu(&#39;divAbstract2007_iscas&#39;)">Abstract</a>]
                        [<a style="CURSOR: pointer" class="aLink" title="Show/Hide BibTeX" onclick="JavaScript:menu(&#39;divBibTex2007_iscas&#39;)">BibTeX</a>]
<!--                        [<a class="aLink" title="Download Slides" href="./2007_iscas_lecture.pdf" target="_blank">Slides</a>]
                        [<a class="aLink" title="Download Full Text" href="./2007_iscas.pdf" target="_blank">Full Text</a>] -->
                        <br>
                        
                        
                        </td></tr>
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
		      <td width="304px"> </td> 
                      <td class="pub_td_text"> <strong>Wanli Ouyang</strong>, D. Song, C. Xiao, and W. Ju. 
                      	The matrix decomposition representation of DCT algorithms. 
                      	In <em>IEEE midwest sym. Circuits and Syst.</em> (MWCAS), 2005.
                        <br>            
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
		      <td width="304px"> </td> 
                      <td class="pub_td_text"> <strong>Wanli Ouyang</strong>, C. Xiao, W. Ju, and D. Song. The dynamic range acquisition of DCT and IDCT algorithms. 
                      	In <em>IEEE midwest sym. Circuits and Syst. </em> (MWCAS), 2005.
                        <br>            
                    <tr class="pub_tr_1">
                      <td width="20px" class="pub_td_number"> </td>
		      <td width="304px"> </td> 
                      <td class="pub_td_text"> <strong>Wanli Ouyang</strong>, C. Xiao, W. Ju, and D. Song. Practical fast asymmetric DCT algorithm based on SIMD and VLIW. 
                      	In <em>IEEE Int. Sym. Intelligent Signal Processing </em>, 2005.
                        <br>            
                        
                    <tr class="pub_tr_1">  
                      <td width="20%" align="left" colspan="2" style="HEIGHT:10px"></td></tr>
                    <tr class="pub_tr_1">  
                      <td width="20%" align="left" colspan="2"><a class="aLink" href="./#Top">Back To Top</a></td></tr>
                    </tbody></table>
</div>
                    
</td></tr></tbody></table>
<!--================================End of Body of Windows Body====================================-->
<!--================================Begin of Footer of Windows Body====================================-->
      <center>
      <table border="0" cellspacing="0" cellpadding="0" width="900px" style="BACKGROUND-IMAGE: url(footer_bg.jpg); COLOR: #2b547e">
        <tbody>
        <tr style="VERTICAL-ALIGN: middle">
<!--          <td style="TEXT-ALIGN: right; WIDTH: 200px; HEIGHT: 30px">
          <img alt="AVSX.org" src="avsx_logo_small.gif"></td> -->
          <td class="i_td_windows_footer">
          Last Update: Apr. 2013. Copyright © 2013-. 
          <a href="http://validator.w3.org/check?uri=./saved_resource.htm">
          <img style="BORDER-BOTTOM: 0px; BORDER-LEFT: 0px; WIDTH: 45px; HEIGHT: 15px; BORDER-TOP: 0px; BORDER-RIGHT: 0px" alt="Valid HTML 4.01 Transitional" src="valid-html401-blue.png"></a> 
          <a href="http://jigsaw.w3.org/css-validator/validator?uri=./saved_resource.htm">
          <img style="BORDER-BOTTOM: 0px; BORDER-LEFT: 0px; WIDTH: 45px; HEIGHT: 15px; BORDER-TOP: 0px; BORDER-RIGHT: 0px" alt="Valid CSS!" src="valid-css-blue.png"></a>
            </td>
        </tr>
        </tbody>
      </table>
      </center>
<!--================================End of Footer of Windows Body====================================-->
	  </center>
    </td>
  </tr>
  </tbody>
</table>



<script>
  // generate publication list from data.json
    "use strict"


    function readTextFile(file, callback) {
      var rawFile = new XMLHttpRequest();
      rawFile.overrideMimeType("application/json");
      rawFile.open("GET", file, false); //fase for synchronous requests
      rawFile.onreadystatechange = function() {
          if (rawFile.readyState === 4 && rawFile.status == "200") {
            callback(rawFile.responseText);
          }
      }
      rawFile.send(null);
    }
    let journal_data;
    let conference_data;
    readTextFile('https://raw.githubusercontent.com/wlouyang/wlouyang.github.io/master/data.json', function(text){
      let data = JSON.parse(text);
      journal_data = data.journals;
      conference_data = data.conferences;
    });


    function journalPubItemConstructor(pubitem) {
      let obj;
      obj = document.createElement('template');
      let html_template = `
        <tr class="pub_tr_2">
        <td width="20px" class="pub_td_number">  </td>
        <td width="304px" style="text-align: center"> <img style="width: 336Px;" alt="Wanli" src="IMAGE" width="336px" height="200px"> </td>
        <td width="500px" style="vertical-align: middle" class="pub_td_text"> 
        AUTHORS, "TITLE"  JOURNAL
          [<a class="aLink" href="#" target="_blank">Full Text</a>]
          <br>
        </td></tr>
      `;
      obj.innerHTML = html_template
      .replace("AUTHORS", pubitem.authors)
      .replace("TITLE", pubitem.title)
      .replace("JOURNAL", pubitem.journal)
      .replace("IMAGE", pubitem.image)
      .replace(`<img style="width: 336Px;" alt="Wanli" src="" width="336px" height="200px">`, "");

      return obj.content.firstElementChild;
    }

    function conferencePubItemConstructor(pubitem) {
      let obj = document.createElement('template');
      let html_template = `
      <tr class="pub_tr_2">
      <td width="20px" class="pub_td_number"> </td>
      <td width="304px" style="vertical-align: middle"> MAIN_IMAGES
      </td>

      <td class="pub_td_text" width="500px" style="vertical-align: middle"> 
        PAPER_LIST                        
      </td>
      </tr>
      `

      let image_list = "";
      let main_image;
      for (main_image of pubitem.main_images) {
        image_list += `<img alt="" border="0" src="${main_image}" width="304px" height="200" >`
      }


      let paper_list = "";
      let paper;
      for (paper of pubitem.papers) {
        paper_list += `
          <br>
          ${paper.authors}, "${paper.title}", ${paper.conference}
          <br>
        `
      }

      obj.innerHTML = html_template
      .replace("MAIN_IMAGES", image_list)
      .replace("PAPER_LIST", paper_list);

      return obj.content.firstElementChild;
    }

    //Journal list generation
    let journal_list = document.getElementById("journal_list");
    let pubitem;
    for (pubitem of journal_data.reverse()) {
      journal_list.prepend(journalPubItemConstructor(pubitem))
    }

    let conference_list = document.getElementById("conference_list");
    for (pubitem of conference_data.reverse()) {
      conference_list.prepend(conferencePubItemConstructor(pubitem))
    }

    //Conference list generation




  </script>

</body></html>